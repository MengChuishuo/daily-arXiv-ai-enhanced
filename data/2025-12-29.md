<div id=toc></div>

# Table of Contents

- [stat.ML](#stat.ML) [Total: 2]
- [cs.LG](#cs.LG) [Total: 30]
- [physics.soc-ph](#physics.soc-ph) [Total: 4]
- [cs.AI](#cs.AI) [Total: 9]
- [q-fin.CP](#q-fin.CP) [Total: 1]


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [1] [An approach to Fisher-Rao metric for infinite dimensional non-parametric information geometry](https://arxiv.org/abs/2512.21451)
*Bing Cheng,Howell Tong*

Main category: stat.ML

TL;DR: 该论文提出了一种解决非参数信息几何中Fisher-Rao度量不可计算问题的新框架，通过切空间正交分解得到可计算的协变量Fisher信息矩阵，建立了G-熵的几何基础，并连接了协变量Cramér-Rao下界和流形假设。


<details>
  <summary>Details</summary>
Motivation: 非参数信息几何长期面临"不可计算性障碍"，因为Fisher-Rao度量是泛函，难以定义其逆。现有方法无法有效处理高维非参数模型的几何结构，限制了信息几何在可解释AI中的应用。

Method: 提出切空间正交分解框架(T_fM=S⊕S^⊥)，其中S表示可观测协变量子空间。通过该分解推导出协变量Fisher信息矩阵(cFIM)，这是一个有限维且可计算的信息几何表示。建立了迹定理证明G-熵的几何基础，连接cFIM与KL散度的二阶导数，提出协变量Cramér-Rao下界。

Result: 证明了cFIM与有效Fisher信息矩阵同构，为半参数估计量提供了方差的基本极限。将流形假设从启发式假设提升为cFIM中秩亏缺的可检验条件，通过定义信息捕获比提供了估计高维数据内在维度的严格方法。

Conclusion: 该工作通过提供可计算的路径，弥合了抽象信息几何与可解释AI需求之间的差距，为揭示非参数模型的统计覆盖范围和效率提供了理论基础，使信息几何能够实际应用于高维数据分析。

Abstract: Being infinite dimensional, non-parametric information geometry has long faced an "intractability barrier" due to the fact that the Fisher-Rao metric is now a functional incurring difficulties in defining its inverse. This paper introduces a novel framework to resolve the intractability with an Orthogonal Decomposition of the Tangent Space ($T_fM=S \oplus S^{\perp}$), where S represents an observable covariate subspace. Through the decomposition, we derive the Covariate Fisher Information Matrix (cFIM), denoted as $G_f$, which is a finite-dimensional and computable representative of information extractable from the manifold's geometry. Indeed, by proving the Trace Theorem: $H_G(f)=\text{Tr}(G_f)$, we establish a rigorous foundation for the G-entropy previously introduced by us, thereby identifying it not merely as a gradient-based regularizer, but also as a fundamental geometric invariant representing the total explainable statistical information captured by the probability distribution associated with the model. Furthermore, we establish a link between $G_f$ and the second-order derivative (i.e. the curvature) of the KL-divergence, leading to the notion of Covariate Cramér-Rao Lower Bound(CRLB). We demonstrate that $G_f$ is congruent to the Efficient Fisher Information Matrix, thereby providing fundamental limits of variance for semi-parametric estimators. Finally, we apply our geometric framework to the Manifold Hypothesis, lifting the latter from a heuristic assumption into a testable condition of rank-deficiency within the cFIM. By defining the Information Capture Ratio, we provide a rigorous method for estimating intrinsic dimensionality in high-dimensional data. In short, our work bridges the gap between abstract information geometry and the demand of explainable AI, by providing a tractable path for revealing the statistical coverage and the efficiency of non-parametric models.

</details>


### [2] [Tilt Matching for Scalable Sampling and Fine-Tuning](https://arxiv.org/abs/2512.21829)
*Peter Potaptchik,Cheuk-Kit Lee,Michael S. Albergo*

Main category: stat.ML

TL;DR: 提出Tilt Matching算法，通过随机插值器从非归一化密度采样并微调生成模型，无需奖励梯度或反向传播，在Lennard-Jones势采样和Stable Diffusion微调中取得优异效果


<details>
  <summary>Details</summary>
Motivation: 现有方法在从非归一化密度采样和微调生成模型时，通常需要访问奖励梯度或进行复杂的反向传播，计算成本高且实现复杂。需要一种简单、可扩展的算法来解决这些问题。

Method: 提出Tilt Matching算法，基于随机插值器建立动力学方程，将流匹配速度与目标分布（通过奖励倾斜）相关联，隐式解决随机最优控制问题。新速度继承随机插值器传输的规律性，同时最小化方差低于流匹配本身的目标函数。

Result: 算法在Lennard-Jones势采样中取得最先进结果，在Stable Diffusion微调中具有竞争力，无需奖励乘子。方法高效、可扩展，可直接应用于倾斜少步流映射模型。

Conclusion: Tilt Matching提供了一种简单、可扩展的方法，用于从非归一化密度采样和微调生成模型，无需奖励梯度或反向传播，在多个任务中表现出优异性能。

Abstract: We propose a simple, scalable algorithm for using stochastic interpolants to sample from unnormalized densities and for fine-tuning generative models. The approach, Tilt Matching, arises from a dynamical equation relating the flow matching velocity to one targeting the same distribution tilted by a reward, implicitly solving a stochastic optimal control problem. The new velocity inherits the regularity of stochastic interpolant transports while also being the minimizer of an objective with strictly lower variance than flow matching itself. The update to the velocity field can be interpreted as the sum of all joint cumulants of the stochastic interpolant and copies of the reward, and to first order is their covariance. The algorithms do not require any access to gradients of the reward or backpropagating through trajectories of the flow or diffusion. We empirically verify that the approach is efficient and highly scalable, providing state-of-the-art results on sampling under Lennard-Jones potentials and is competitive on fine-tuning Stable Diffusion, without requiring reward multipliers. It can also be straightforwardly applied to tilting few-step flow map models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [First Provable Guarantees for Practical Private FL: Beyond Restrictive Assumptions](https://arxiv.org/abs/2512.21521)
*Egor Shulgin,Grigory Malinovsky,Sarit Khirirat,Peter Richtárik*

Main category: cs.LG

TL;DR: Fed-α-NormEC是首个在标准假设下提供可证明收敛性和差分隐私保证的联邦学习框架，完全支持多轮本地更新和部分客户端参与等实际特征。


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习中的差分隐私方法依赖不现实的假设（如梯度有界或同质性），且通常忽略实际联邦学习特征如多轮本地更新和部分客户端参与，这阻碍了实际应用。

Method: 提出Fed-α-NormEC框架，整合本地更新（完整和增量梯度步骤）、独立的服务器和客户端步长，以及关键的部分客户端参与机制。

Result: 该框架在标准假设下提供可证明的收敛性和差分隐私保证，并通过私有深度学习任务的实验验证了理论保证。

Conclusion: Fed-α-NormEC是首个完全支持实际联邦学习特征并提供严格隐私保证的差分隐私联邦学习框架，对现实世界部署具有重要意义。

Abstract: Federated Learning (FL) enables collaborative training on decentralized data. Differential privacy (DP) is crucial for FL, but current private methods often rely on unrealistic assumptions (e.g., bounded gradients or heterogeneity), hindering practical application. Existing works that relax these assumptions typically neglect practical FL features, including multiple local updates and partial client participation. We introduce Fed-$α$-NormEC, the first differentially private FL framework providing provable convergence and DP guarantees under standard assumptions while fully supporting these practical features. Fed-$α$-NormE integrates local updates (full and incremental gradient steps), separate server and client stepsizes, and, crucially, partial client participation, which is essential for real-world deployment and vital for privacy amplification. Our theoretical guarantees are corroborated by experiments on private deep learning tasks.

</details>


### [4] [A Reinforcement Learning Approach to Synthetic Data Generation](https://arxiv.org/abs/2512.21395)
*Natalia Espinosa-Dice,Nicholas J. Jackson,Chao Yan,Aaron Lee,Bradley A. Malin*

Main category: cs.LG

TL;DR: RLSyn：将合成数据生成重构为强化学习问题，在小样本生物医学数据场景中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有生成模型需要大量数据和复杂训练，限制了在小样本生物医学研究中的应用，需要更高效的数据生成方法

Method: 将合成数据生成重构为强化学习问题，使用基于判别器奖励的近端策略优化训练随机策略生成患者记录

Result: 在MIMIC-IV上与扩散模型相当且优于GANs，在较小的AI-READI数据集上优于扩散模型和GANs

Conclusion: 强化学习为合成生物医学数据生成提供了原则性有效替代方案，特别适用于数据稀缺场景

Abstract: Synthetic data generation (SDG) is a promising approach for enabling data sharing in biomedical studies while preserving patient privacy. Yet, state-of-the-art generative models often require large datasets and complex training procedures, limiting their applicability in small-sample settings. In this work, we reframe SDG as a reinforcement learning (RL) problem and introduce RLSyn, a novel framework that models the data generator as a stochastic policy over patient records and optimizes it using Proximal Policy Optimization with discriminator-derived rewards, yielding more stable and data-efficient training. We evaluate RLSyn on two biomedical datasets - AI-READI and MIMIC-IV- and benchmark it against state-of-the-art generative adversarial networks (GANs) and diffusion-based methods across extensive privacy, utility, and fidelity evaluations. RL-Syn performs comparably to diffusion models and outperforms GANs on MIMIC-IV, while outperforming both diffusion models and GANs on the smaller AI-READI dataset. These results demonstrate that reinforcement learning provides a principled and effective alternative for synthetic biomedical data generation, particularly in data-scarce regimes.

</details>


### [5] [Synthetic Financial Data Generation for Enhanced Financial Modelling](https://arxiv.org/abs/2512.21791)
*Christophe D. Hounwanou,Yae Ulrich Gaba,Pierre Ntakirutimana*

Main category: cs.LG

TL;DR: 论文提出了一个统一的合成金融数据多标准评估框架，并应用于三种生成范式：ARIMA-GARCH、VAE和TimeGAN，通过S&P 500数据评估其保真度、时间结构和下游任务实用性。


<details>
  <summary>Details</summary>
Motivation: 金融领域的数据稀缺性和机密性阻碍了模型开发和稳健测试，需要系统评估合成金融数据的质量。

Method: 使用统一的评估框架，对三种生成模型（ARIMA-GARCH、VAE、TimeGAN）在S&P 500历史数据上进行评估，包括保真度（MMD）、时间结构（自相关和波动率聚类）以及下游任务实用性（均值-方差投资组合优化和波动率预测）。

Result: ARIMA-GARCH能捕捉线性趋势和条件波动率但无法重现非线性动态；VAE产生平滑轨迹但低估极端事件；TimeGAN在真实性和时间连贯性之间达到最佳平衡（MMD最低：1.84e-3）。

Conclusion: 提出了根据应用需求和计算约束选择生成模型的实用指南，统一的评估协议和可复现代码库旨在标准化合成金融数据研究的基准测试。

Abstract: Data scarcity and confidentiality in finance often impede model development and robust testing. This paper presents a unified multi-criteria evaluation framework for synthetic financial data and applies it to three representative generative paradigms: the statistical ARIMA-GARCH baseline, Variational Autoencoders (VAEs), and Time-series Generative Adversarial Networks (TimeGAN). Using historical S and P 500 daily data, we evaluate fidelity (Maximum Mean Discrepancy, MMD), temporal structure (autocorrelation and volatility clustering), and practical utility in downstream tasks, specifically mean-variance portfolio optimization and volatility forecasting. Empirical results indicate that ARIMA-GARCH captures linear trends and conditional volatility but fails to reproduce nonlinear dynamics; VAEs produce smooth trajectories that underestimate extreme events; and TimeGAN achieves the best trade-off between realism and temporal coherence (e.g., TimeGAN attained the lowest MMD: 1.84e-3, average over 5 seeds). Finally, we articulate practical guidelines for selecting generative models according to application needs and computational constraints. Our unified evaluation protocol and reproducible codebase aim to standardize benchmarking in synthetic financial data research.

</details>


### [6] [kooplearn: A Scikit-Learn Compatible Library of Algorithms for Evolution Operator Learning](https://arxiv.org/abs/2512.21409)
*Giacomo Turri,Grégoire Pacreau,Giacomo Meanti,Timothée Devergne,Daniel Ordonez,Erfan Mirzaei,Bruno Belucci,Karim Lounici,Vladimir Kostic,Massimiliano Pontil,Pietro Novelli*

Main category: cs.LG

TL;DR: kooplearn是一个机器学习库，实现了线性、核和深度学习估计器，用于估计动态算子及其谱分解，支持离散时间演化算子和连续时间无穷小生成元，兼容scikit-learn API。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的机器学习库，用于学习动态系统的算子，支持谱分析、降阶建模和预测，同时提供与现有机器学习工作流兼容的接口和基准数据集。

Method: 实现线性、核和深度学习估计器来估计Koopman/Transfer算子和连续时间无穷小生成元，提供scikit-learn兼容的API，并包含精选的基准数据集。

Result: 开发了kooplearn库，支持动态系统的算子学习和谱分解，可用于系统分析、降阶建模和预测，提供了开源软件实现和基准数据集。

Conclusion: kooplearn是一个功能完整的机器学习库，为动态系统分析提供了统一的工具集，通过兼容scikit-learn API和提供基准数据集，促进了算法比较和可重复性研究。

Abstract: kooplearn is a machine-learning library that implements linear, kernel, and deep-learning estimators of dynamical operators and their spectral decompositions. kooplearn can model both discrete-time evolution operators (Koopman/Transfer) and continuous-time infinitesimal generators. By learning these operators, users can analyze dynamical systems via spectral methods, derive data-driven reduced-order models, and forecast future states and observables. kooplearn's interface is compliant with the scikit-learn API, facilitating its integration into existing machine learning and data science workflows. Additionally, kooplearn includes curated benchmark datasets to support experimentation, reproducibility, and the fair comparison of learning algorithms. The software is available at https://github.com/Machine-Learning-Dynamical-Systems/kooplearn.

</details>


### [7] [dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning](https://arxiv.org/abs/2512.21446)
*Shirui Chen,Jiantao Jiao,Lillian J. Ratliff,Banghua Zhu*

Main category: cs.LG

TL;DR: dUltra是一个基于强化学习的框架，通过优化解掩码策略实现扩散语言模型的并行解码加速，在数学推理和代码生成任务上超越了现有启发式和蒸馏方法。


<details>
  <summary>Details</summary>
Motivation: 现有的掩码扩散语言模型(MDLMs)即使采用复杂采样策略，每次前向传播也只能解码不到5个token，采样速度与自回归模型+推测解码方案相当，限制了其相对于主流自回归方法的优势。现有的基于蒸馏的加速方法(dParallel, d3LLM)在基础模型生成的轨迹上进行微调，可能在微调过程中偏离策略，且性能受限于基础模型样本质量。

Method: 提出dUltra框架，基于组相对策略优化(GRPO)的在线强化学习方法，学习高效并行解码的解掩码策略。引入解掩码规划器头，在独立伯努利分布下预测每个token的解掩码概率。联合优化基础扩散LLM和解掩码顺序规划器，使用包含可验证奖励、蒸馏奖励和解掩码步骤数的组合奖励信号。

Result: 在数学推理和代码生成任务上，dUltra在准确率-效率权衡方面超越了最先进的启发式和蒸馏基线方法，朝着实现"扩散优势"超越自回归模型的方向迈进。

Conclusion: dUltra通过强化学习框架优化解掩码策略，显著提升了掩码扩散语言模型的并行解码效率，在保持准确性的同时提高了采样速度，为实现扩散模型相对于自回归模型的优势提供了有效途径。

Abstract: Masked diffusion language models (MDLMs) offer the potential for parallel token generation, but most open-source MDLMs decode fewer than 5 tokens per model forward pass even with sophisticated sampling strategies. As a result, their sampling speeds are often comparable to AR + speculative decoding schemes, limiting their advantage over mainstream autoregressive approaches. Existing distillation-based accelerators (dParallel, d3LLM) finetune MDLMs on trajectories generated by a base model, which can become off-policy during finetuning and restrict performance to the quality of the base model's samples. We propose \texttt{dUltra}, an on-policy reinforcement learning framework based on Group Relative Policy Optimization (GRPO) that learns unmasking strategies for efficient parallel decoding. dUltra introduces an unmasking planner head that predicts per-token unmasking likelihoods under independent Bernoulli distributions. We jointly optimize the base diffusion LLM and the unmasking order planner using reward signals combining verifiable reward, distillation reward, and the number of unmasking steps. Across mathematical reasoning and code generation tasks, dUltra improves the accuracy--efficiency trade-off over state-of-the-art heuristic and distillation baselines, moving towards achieving ``diffusion supremacy'' over autoregressive models.

</details>


### [8] [RLLaVA: An RL-central Framework for Language and Vision Assistants](https://arxiv.org/abs/2512.21450)
*Lei Zhao,Zihao Ma,Boyu Lin,Yuhe Liu,Wenjun Wu,Lei Huang*

Main category: cs.LG

TL;DR: RLLaVA是一个用于语言视觉助手的强化学习框架，通过MDP公式化，将RL算法逻辑与模型架构和执行解耦，支持研究人员用最少代码实现新RL算法，并兼容多种RL方法和视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有的RL框架通常与特定模型架构和训练引擎紧密耦合，限制了研究灵活性。需要一种能够解耦RL算法逻辑、支持多种VLMs、并在有限资源下高效训练大模型的框架。

Method: 提出基于马尔可夫决策过程(MDP)的RL框架，将算法逻辑与模型架构和分布式执行分离。支持多种RL方法和视觉语言模型，保持对特定训练和推理引擎的不可知性。

Result: RLLaVA能在普通GPU上高效训练1B-7B参数模型，4B规模模型可在单张24GB GPU上端到端全参数更新。在多模态和智能体任务上表现优于基础模型，与其他专门设计的RL框架竞争力相当。

Conclusion: RLLaVA提供了一个灵活、高效的RL框架，支持快速算法开发和模型训练，为语言视觉助手的研究提供了实用工具，代码已开源。

Abstract: We present an RL-central framework for Language and Vision Assistants (RLLaVA) with its formulation of Markov decision process (MDP). RLLaVA decouples RL algorithmic logic from model architecture and distributed execution, supporting researchers in implementing new RL algorithms with minimal code, and to plug in a broad family of RL methods and vision-language models (VLMs) while remaining agnostic to specific training and inference engines. RLLaVA makes resource-efficient training of 1B--7B models feasible on common GPUs; notably, 4B-scale models can be trained end-to-end with full-parameter updates on a single 24GB GPU. Experiments on multi-modal and agentic tasks demonstrate that RLLaVA has task extensibility, and the models trained with it consistently improve performance over base models, competitive with other specially engineered RL frameworks. The code is available at https://github.com/TinyLoopX/RLLaVA.

</details>


### [9] [Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US](https://arxiv.org/abs/2512.21456)
*Sukanya Krishna,Marie-Laure Charpignon,Maimuna Majumder*

Main category: cs.LG

TL;DR: 深度学习模型（特别是LSTM）在预测美国药物过量死亡率方面优于传统SARIMA方法，在结构变化时期提供更准确的点估计和更好的不确定性校准。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行加剧了药物过量死亡趋势，但传统统计方法（如SARIMA）假设线性、平稳和固定季节性，在结构性中断时期可能不适用。需要更准确的方法来估计超额死亡率，以了解大流行影响并指导干预策略。

Method: 系统比较SARIMA与三种深度学习架构（LSTM、Seq2Seq和Transformer），使用CDC国家数据（2015-2019年训练/验证，2020-2023年预测）。采用可重复流程，包含符合预测区间和60多次试验的收敛分析，提供开源框架。

Result: LSTM在点估计方面表现最优（MAPE 17.08% vs SARIMA 23.88%），不确定性校准更好（预测区间覆盖率68.8% vs 47.9%）。注意力模型（Seq2Seq、Transformer）表现不佳，因为它们过度拟合历史均值而非捕捉新兴趋势。

Conclusion: 经过仔细验证的深度学习模型可以提供比传统方法更可靠的反事实估计，用于公共卫生规划。在高风险领域部署神经预测时，需要校准技术。研究提供了可部署到15个州卫生部门的开源框架。

Abstract: Substance overdose mortality in the United States claimed over 80,000 lives in 2023, with the COVID-19 pandemic exacerbating existing trends through healthcare disruptions and behavioral changes. Estimating excess mortality, defined as deaths beyond expected levels based on pre-pandemic patterns, is essential for understanding pandemic impacts and informing intervention strategies. However, traditional statistical methods like SARIMA assume linearity, stationarity, and fixed seasonality, which may not hold under structural disruptions. We present a systematic comparison of SARIMA against three deep learning (DL) architectures (LSTM, Seq2Seq, and Transformer) for counterfactual mortality estimation using national CDC data (2015-2019 for training/validation, 2020-2023 for projection). We contribute empirical evidence that LSTM achieves superior point estimation (17.08% MAPE vs. 23.88% for SARIMA) and better-calibrated uncertainty (68.8% vs. 47.9% prediction interval coverage) when projecting under regime change. We also demonstrate that attention-based models (Seq2Seq, Transformer) underperform due to overfitting to historical means rather than capturing emergent trends. Ourreproducible pipeline incorporates conformal prediction intervals and convergence analysis across 60+ trials per configuration, and we provide an open-source framework deployable with 15 state health departments. Our findings establish that carefully validated DL models can provide more reliable counterfactual estimates than traditional methods for public health planning, while highlighting the need for calibration techniques when deploying neural forecasting in high-stakes domains.

</details>


### [10] [MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding](https://arxiv.org/abs/2512.21506)
*Aiwei Zhang,Arvind Pillai,Andrew Campbell,Nicholas C. Jacobson*

Main category: cs.LG

TL;DR: MotionTeller是一个生成框架，将可穿戴活动数据与大型语言模型集成，从原始生理信号生成自然语言行为摘要。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴传感的普及，如何从原始生理信号（如加速度计收集的分钟级运动数据）生成自然语言摘要成为一个关键挑战。

Method: 结合预训练的活动记录编码器和轻量级投影模块，将行为嵌入映射到冻结解码器LLM的标记空间，使用交叉熵损失训练，仅对语言标记进行监督。

Result: 在54383个真实世界NHANES记录数据集上，MotionTeller实现高语义保真度（BERTScore-F1 = 0.924）和词汇准确性（ROUGE-1 = 0.722），优于基于提示的基线7%。

Conclusion: MotionTeller作为一个可扩展、可解释的系统，能够将可穿戴传感器数据转化为流畅、以人为中心的描述，为行为监测、临床审查和个性化健康干预开辟新途径。

Abstract: As wearable sensing becomes increasingly pervasive, a key challenge remains: how can we generate natural language summaries from raw physiological signals such as actigraphy - minute-level movement data collected via accelerometers? In this work, we introduce MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs). MotionTeller combines a pretrained actigraphy encoder with a lightweight projection module that maps behavioral embeddings into the token space of a frozen decoder-only LLM, enabling free-text, autoregressive generation of daily behavioral summaries. We construct a novel dataset of 54383 (actigraphy, text) pairs derived from real-world NHANES recordings, and train the model using cross-entropy loss with supervision only on the language tokens. MotionTeller achieves high semantic fidelity (BERTScore-F1 = 0.924) and lexical accuracy (ROUGE-1 = 0.722), outperforming prompt-based baselines by 7 percent in ROUGE-1. The average training loss converges to 0.38 by epoch 15, indicating stable optimization. Qualitative analysis confirms that MotionTeller captures circadian structure and behavioral transitions, while PCA plots reveal enhanced cluster alignment in embedding space post-training. Together, these results position MotionTeller as a scalable, interpretable system for transforming wearable sensor data into fluent, human-centered descriptions, introducing new pathways for behavioral monitoring, clinical review, and personalized health interventions.

</details>


### [11] [Missing Pattern Tree based Decision Grouping and Ensemble for Deep Incomplete Multi-View Clustering](https://arxiv.org/abs/2512.21510)
*Wenyuan Yang,Jie Xu,Hongqing He,Jiangzhang Gan,Xiaofeng Zhu*

Main category: cs.LG

TL;DR: TreeEIC提出了一种基于缺失模式树的IMVC框架，通过分组决策集、决策集成和知识蒸馏，充分利用不完整多视图数据中的可用视图对，解决了现有方法对可用视图对利用不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界多视图数据通常存在高度不一致的缺失模式，挑战了不完整多视图聚类（IMVC）的有效性。现有IMVC方法虽然从基于插补和无插补两条路线取得进展，但忽视了"视图对利用不足"问题——不一致的缺失模式使得不完整但可用的多视图对无法被充分利用，从而限制了模型性能。

Method: 1. 定义缺失模式树模型，根据不同的缺失模式将数据分组到多个决策集中；2. 在每个决策集内执行多视图聚类；3. 提出多视图决策集成模块，聚合所有决策集的聚类结果，通过基于不确定性的权重抑制不可靠的聚类决策；4. 设计集成到个体的知识蒸馏模块，将集成知识转移到视图特定的聚类模型中，通过优化跨视图一致性和簇间判别损失实现集成与个体模块的相互促进。

Result: 在多个基准数据集上的大量实验表明，TreeEIC实现了最先进的IMVC性能，并在高度不一致的缺失模式下表现出优越的鲁棒性。

Conclusion: TreeEIC通过缺失模式树模型、决策集成和知识蒸馏的协同设计，有效解决了IMVC中视图对利用不足的问题，为高度不一致缺失模式下的多视图聚类提供了有效的解决方案。

Abstract: Real-world multi-view data usually exhibits highly inconsistent missing patterns which challenges the effectiveness of incomplete multi-view clustering (IMVC). Although existing IMVC methods have made progress from both imputation-based and imputation-free routes, they have overlooked the pair under-utilization issue, i.e., inconsistent missing patterns make the incomplete but available multi-view pairs unable to be fully utilized, thereby limiting the model performance. To address this, we propose a novel missing-pattern tree based IMVC framework entitled TreeEIC. Specifically, to achieve full exploitation of available multi-view pairs, TreeEIC first defines the missing-pattern tree model to group data into multiple decision sets according to different missing patterns, and then performs multi-view clustering within each set. Furthermore, a multi-view decision ensemble module is proposed to aggregate clustering results from all decision sets, which infers uncertainty-based weights to suppress unreliable clustering decisions and produce robust decisions. Finally, an ensemble-to-individual knowledge distillation module transfers the ensemble knowledge to view-specific clustering models, which enables ensemble and individual modules to promote each other by optimizing cross-view consistency and inter-cluster discrimination losses. Extensive experiments on multiple benchmark datasets demonstrate that our TreeEIC achieves state-of-the-art IMVC performance and exhibits superior robustness under highly inconsistent missing patterns.

</details>


### [12] [Global-Graph Guided and Local-Graph Weighted Contrastive Learning for Unified Clustering on Incomplete and Noise Multi-View Data](https://arxiv.org/abs/2512.21516)
*Hongqing He,Jie Xu,Wenyuan Yang,Yonghua Zhu,Guoqiu Wen,Xiaofeng Zhu*

Main category: cs.LG

TL;DR: 提出了一种统一的对比学习多视图聚类框架，通过全局图引导和局部图加权对比学习来解决不完整和噪声多视图数据中的样本配对问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多视图数据常存在数据不完整或噪声问题，导致样本配对稀少或错误配对，这严重影响了基于对比学习的多视图聚类效果。稀少配对问题阻碍了多视图互补信息的充分提取，而错误配对问题则导致对比学习在错误方向优化模型。

Method: 1. 针对稀少配对问题：设计全局图引导的对比学习，所有视图样本构建全局视图亲和力图，形成新的样本对以充分探索互补信息。
2. 针对错误配对问题：提出局部图加权对比学习，利用局部邻居生成配对权重，自适应地增强或减弱配对对比学习。
3. 该方法无需插补，可集成到统一的全局-局部图引导对比学习框架中。

Result: 在不完整和噪声设置下的多视图数据上进行了大量实验，结果表明该方法相比最先进方法取得了优越的性能。

Conclusion: 提出的统一对比学习多视图聚类框架有效解决了不完整和噪声多视图数据中的样本配对问题，通过全局图引导和局部图加权机制显著提升了聚类效果。

Abstract: Recently, contrastive learning (CL) plays an important role in exploring complementary information for multi-view clustering (MVC) and has attracted increasing attention. Nevertheless, real-world multi-view data suffer from data incompleteness or noise, resulting in rare-paired samples or mis-paired samples which significantly challenges the effectiveness of CL-based MVC. That is, rare-paired issue prevents MVC from extracting sufficient multi-view complementary information, and mis-paired issue causes contrastive learning to optimize the model in the wrong direction. To address these issues, we propose a unified CL-based MVC framework for enhancing clustering effectiveness on incomplete and noise multi-view data. First, to overcome the rare-paired issue, we design a global-graph guided contrastive learning, where all view samples construct a global-view affinity graph to form new sample pairs for fully exploring complementary information. Second, to mitigate the mis-paired issue, we propose a local-graph weighted contrastive learning, which leverages local neighbors to generate pair-wise weights to adaptively strength or weaken the pair-wise contrastive learning. Our method is imputation-free and can be integrated into a unified global-local graph-guided contrastive learning framework. Extensive experiments on both incomplete and noise settings of multi-view data demonstrate that our method achieves superior performance compared with state-of-the-art approaches.

</details>


### [13] [Generative Actor Critic](https://arxiv.org/abs/2512.21527)
*Aoyang Qin,Deqian Kong,Wei Wang,Ying Nian Wu,Song-Chun Zhu,Sirui Xie*

Main category: cs.LG

TL;DR: GAC是一种新的强化学习框架，将策略评估重构为学习轨迹和回报的联合分布生成模型，将策略改进重构为对该模型进行推理，显著提升了离线到在线学习的性能。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习算法专注于估计或最大化期望回报，在将离线预训练模型与在线经验结合时面临挑战，需要新的框架来更好地整合离线学习和在线改进。

Method: 提出生成式行动者-评论家(GAC)框架，将策略评估重构为学习轨迹和回报的联合分布p(τ,y)，将策略改进重构为对该学习模型进行推理。具体实现基于具有连续潜在计划向量的潜变量模型，开发了用于利用（优化潜在计划以最大化期望回报）和探索（基于动态调整的目标回报采样潜在计划）的新型推理策略。

Result: 在Gym-MuJoCo和Maze2D基准测试中，GAC展现出强大的离线性能，并且在离线到在线改进方面显著优于最先进的方法，即使在缺乏逐步奖励的情况下也表现良好。

Conclusion: GAC通过将序列决策解耦为生成建模和推理任务，提供了一种灵活且有效的强化学习框架，特别适用于将离线预训练模型与在线经验相结合的场景。

Abstract: Conventional Reinforcement Learning (RL) algorithms, typically focused on estimating or maximizing expected returns, face challenges when refining offline pretrained models with online experiences. This paper introduces Generative Actor Critic (GAC), a novel framework that decouples sequential decision-making by reframing \textit{policy evaluation} as learning a generative model of the joint distribution over trajectories and returns, $p(τ, y)$, and \textit{policy improvement} as performing versatile inference on this learned model. To operationalize GAC, we introduce a specific instantiation based on a latent variable model that features continuous latent plan vectors. We develop novel inference strategies for both \textit{exploitation}, by optimizing latent plans to maximize expected returns, and \textit{exploration}, by sampling latent plans conditioned on dynamically adjusted target returns. Experiments on Gym-MuJoCo and Maze2D benchmarks demonstrate GAC's strong offline performance and significantly enhanced offline-to-online improvement compared to state-of-the-art methods, even in absence of step-wise rewards.

</details>


### [14] [AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification](https://arxiv.org/abs/2512.21544)
*Xinru Wen,Weizhong Lin,Xuan Xiao*

Main category: cs.LG

TL;DR: AVP-Fusion是一个两阶段深度学习框架，通过自适应特征融合和对比学习准确识别抗病毒肽，显著优于现有方法，并支持病毒家族和特定病毒的亚类预测。


<details>
  <summary>Details</summary>
Motivation: 当前计算方法难以捕捉复杂的序列依赖关系，无法有效处理模糊、难以分类的样本，这阻碍了新型抗病毒药物的开发进程。

Method: 提出AVP-Fusion两阶段深度学习框架：1) 使用10种不同描述符构建全景特征空间；2) 引入自适应门控机制动态调节CNN提取的局部基序和BiLSTM捕获的全局依赖的权重；3) 采用基于在线困难样本挖掘和BLOSUM62数据增强的对比学习策略；4) 第二阶段利用迁移学习进行病毒家族和特定病毒的亚类预测。

Result: 在基准数据集Set 1上，AVP-Fusion达到0.9531的准确率和0.9064的MCC值，显著优于最先进方法。即使在有限样本情况下，也能准确预测六个病毒家族和八个特定病毒的亚类。

Conclusion: AVP-Fusion作为一个强大且可解释的工具，为高通量抗病毒药物筛选提供了有效解决方案，能够准确识别抗病毒肽并进行精细的病毒亚类预测。

Abstract: Accurate identification of antiviral peptides (AVPs) is critical for accelerating novel drug development. However, current computational methods struggle to capture intricate sequence dependencies and effectively handle ambiguous, hard-to-classify samples. To address these challenges, we propose AVP-Fusion, a novel two-stage deep learning framework integrating adaptive feature fusion and contrastive learning. Unlike traditional static feature concatenation, we construct a panoramic feature space using 10 distinct descriptors and introduce an Adaptive Gating Mechanism.This mechanism dynamically regulates the weights of local motifs extracted by CNNs and global dependencies captured by BiLSTMs based on sequence context. Furthermore, to address data distribution challenges, we employ a contrastive learning strategy driven by Online Hard Example Mining (OHEM) and BLOSUM62-based data augmentation, which significantly sharpens the model's decision boundaries. Experimental results on the benchmark Set 1 dataset demonstrate that AVP-Fusion achieves an accuracy of 0.9531 and an MCC of 0.9064, significantly outperforming state-of-the-art methods. In the second stage, leveraging transfer learning, the model enables precise subclass prediction for six viral families and eight specific viruses, even under limited sample sizes. In summary, AVP-Fusion serves as a robust and interpretable tool for high-throughput antiviral drug screening.

</details>


### [15] [Discovering Sparse Recovery Algorithms Using Neural Architecture Search](https://arxiv.org/abs/2512.21563)
*Patrick Yubeaton,Sarthak Gupta,M. Salman Asif,Chinmay Hegde*

Main category: cs.LG

TL;DR: 本文提出使用元学习工具（如神经架构搜索）自动发现信号处理中的逆问题求解算法，以ISTA和FISTA算法为案例，成功从超过5万个变量的搜索空间中重新发现了这些算法的关键元素。


<details>
  <summary>Details</summary>
Motivation: 设计信号处理中逆问题求解的新算法是一项极其困难、依赖启发式方法且耗时的工作，需要寻找更高效的自动化算法发现方法。

Method: 开发了一个元学习框架，利用神经架构搜索（NAS）等工具，在包含超过50,000个变量的搜索空间中自动发现算法，以ISTA和FISTA算法为具体研究对象。

Result: 该框架成功重新发现了ISTA和FISTA算法的几个关键元素，并展示了该框架可以应用于ISTA/FISTA之外的各种数据分布和算法。

Conclusion: 元学习方法能够有效自动化信号处理算法的发现过程，为算法设计提供了新的高效途径，具有扩展到更广泛算法类别的潜力。

Abstract: The design of novel algorithms for solving inverse problems in signal processing is an incredibly difficult, heuristic-driven, and time-consuming task. In this short paper, we the idea of automated algorithm discovery in the signal processing context through meta-learning tools such as Neural Architecture Search (NAS). Specifically, we examine the Iterative Shrinkage Thresholding Algorithm (ISTA) and its accelerated Fast ISTA (FISTA) variant as candidates for algorithm rediscovery. We develop a meta-learning framework which is capable of rediscovering (several key elements of) the two aforementioned algorithms when given a search space of over 50,000 variables. We then show how our framework can apply to various data distributions and algorithms besides ISTA/FISTA.

</details>


### [16] [Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations](https://arxiv.org/abs/2512.21586)
*Xin Liu,Haoran Li,Dongbin Zhao*

Main category: cs.LG

TL;DR: BCV-LR是一个从视频中进行无监督模仿学习的框架，通过自监督任务提取动作相关潜在特征，利用基于动力学的无监督目标预测潜在动作，然后在线对齐到真实动作空间进行策略行为克隆，实现极高的样本效率。


<details>
  <summary>Details</summary>
Motivation: 人类能够从少量视频中高效提取知识和学习技能，但这对自主智能体来说是一个巨大挑战，因为视觉输入复杂、缺乏动作或奖励信号、交互步骤有限。需要开发能够从视频中进行样本高效模仿学习的方法。

Method: 提出BCV-LR框架：1）通过自监督任务从高维视频输入中提取动作相关潜在特征；2）使用基于动力学的无监督目标预测连续帧之间的潜在动作；3）在线微调并将潜在动作对齐到真实动作空间进行策略行为克隆；4）克隆的策略反过来丰富智能体经验，实现迭代策略改进。

Result: 在离散控制和连续控制的视觉任务上进行广泛实验，BCV-LR仅需少量交互就能实现有效（某些任务达到专家级）策略性能，在24/28任务上超越最先进的ILV基线和强化学习方法（提供环境奖励）的样本效率。

Conclusion: 这项工作首次证明视频可以支持极其样本高效的视觉策略学习，无需访问任何其他专家监督，为从视频中进行无监督模仿学习提供了有效框架。

Abstract: Humans can efficiently extract knowledge and learn skills from the videos within only a few trials and errors. However, it poses a big challenge to replicate this learning process for autonomous agents, due to the complexity of visual input, the absence of action or reward signals, and the limitations of interaction steps. In this paper, we propose a novel, unsupervised, and sample-efficient framework to achieve imitation learning from videos (ILV), named Behavior Cloning from Videos via Latent Representations (BCV-LR). BCV-LR extracts action-related latent features from high-dimensional video inputs through self-supervised tasks, and then leverages a dynamics-based unsupervised objective to predict latent actions between consecutive frames. The pre-trained latent actions are fine-tuned and efficiently aligned to the real action space online (with collected interactions) for policy behavior cloning. The cloned policy in turn enriches the agent experience for further latent action finetuning, resulting in an iterative policy improvement that is highly sample-efficient.
  We conduct extensive experiments on a set of challenging visual tasks, including both discrete control and continuous control. BCV-LR enables effective (even expert-level on some tasks) policy performance with only a few interactions, surpassing state-of-the-art ILV baselines and reinforcement learning methods (provided with environmental rewards) in terms of sample efficiency across 24/28 tasks. To the best of our knowledge, this work for the first time demonstrates that videos can support extremely sample-efficient visual policy learning, without the need to access any other expert supervision.

</details>


### [17] [Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search](https://arxiv.org/abs/2512.21648)
*Maximilian Weichart*

Main category: cs.LG

TL;DR: 本文提出了Inverse-RPO方法，能够从任何无先验UCB中系统性地推导出基于先验的UCT搜索策略，并应用于方差感知的UCB-V得到两种新策略，在多个基准测试中优于PUCT且不增加计算成本。


<details>
  <summary>Details</summary>
Motivation: MCTS在强化学习中通过整合规划和学习对长时程推理任务产生了深远影响。AlphaZero的成功关键是在基于UCB1的树策略PUCT中引入了先验项，提高了探索效率。虽然存在许多比UCB1理论保证更强的替代UCB，但由于PUCT是经验性推导而非基于第一原理，将它们扩展到基于先验的UCT一直具有挑战性。

Method: 基于将MCTS视为正则化策略优化问题的视角，提出了Inverse-RPO方法，这是一种通用方法学，能够从任何无先验UCB中系统性地推导出基于先验的UCT。将此方法应用于方差感知的UCB-V，得到了两种新的基于先验的树策略，将方差估计整合到搜索中。

Result: 实验表明，这些方差感知的基于先验的UCT在多个基准测试中优于PUCT，且不产生额外的计算成本。作者还扩展了mctx库以支持方差感知的UCT，所需的代码改动最小，旨在促进基于先验的UCT的进一步研究。

Conclusion: Inverse-RPO提供了一种系统性的方法来从任何无先验UCB推导基于先验的UCT，通过应用于UCB-V得到的方差感知策略在性能上超越了PUCT，为MCTS搜索策略的设计提供了新的理论框架和实用工具。

Abstract: Monte Carlo Tree Search (MCTS) has profoundly influenced reinforcement learning (RL) by integrating planning and learning in tasks requiring long-horizon reasoning, exemplified by the AlphaZero family of algorithms. Central to MCTS is the search strategy, governed by a tree policy based on an upper confidence bound (UCB) applied to trees (UCT). A key factor in the success of AlphaZero is the introduction of a prior term in the UCB1-based tree policy PUCT, which improves exploration efficiency and thus accelerates training. While many alternative UCBs with stronger theoretical guarantees than UCB1 exist, extending them to prior-based UCTs has been challenging, since PUCT was derived empirically rather than from first principles. Recent work retrospectively justified PUCT by framing MCTS as a regularized policy optimization (RPO) problem. Building on this perspective, we introduce Inverse-RPO, a general methodology that systematically derives prior-based UCTs from any prior-free UCB. Applying this method to the variance-aware UCB-V, we obtain two new prior-based tree policies that incorporate variance estimates into the search. Experiments indicate that these variance-aware prior-based UCTs outperform PUCT across multiple benchmarks without incurring additional computational cost. We also provide an extension of the mctx library supporting variance-aware UCTs, showing that the required code changes are minimal and intended to facilitate further research on principled prior-based UCTs. Code: github.com/Max-We/inverse-rpo.

</details>


### [18] [A Data-Driven Multi-Objective Approach for Predicting Mechanical Performance, Flowability, and Porosity in Ultra-High-Performance Concrete (UHPC)](https://arxiv.org/abs/2512.21610)
*Jagaran Chakma,Zhiguang Zhou,Jyoti Chakma,Cao YuSen*

Main category: cs.LG

TL;DR: 该研究提出了一种数据驱动的多目标方法来预测超高性能混凝土的力学性能、流动性和孔隙率，通过机器学习模型优化和数据处理流程显著提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 减少超高性能混凝土配合比设计中对大量实验测试的需求，通过数据驱动方法提高预测效率和准确性，支持材料设计师进行优化设计。

Method: 采用两阶段流程：1) 从21种机器学习算法中筛选出5个高性能模型，XGBoost表现最佳；2) 数据清洗包括去除多重共线性特征、使用孤立森林识别异常值、SHAP分析选择重要特征，然后重新训练XGBoost模型。开发了图形用户界面支持应用。

Result: XGBoost模型在所有输出指标上均达到高预测精度，经过数据清洗和特征选择后的模型2进一步提升了性能。该方法显著减少了实验测试需求。

Conclusion: 提出的框架显著提高了超高性能混凝土性能预测的准确性，为材料设计提供了高效的数据驱动工具，减少了实验成本和时间。

Abstract: This study presents a data-driven, multi-objective approach to predict the mechanical performance, flow ability, and porosity of Ultra-High-Performance Concrete (UHPC). Out of 21 machine learning algorithms tested, five high-performing models are selected, with XGBoost showing the best accuracy after hyperparameter tuning using Random Search and K-Fold Cross-Validation. The framework follows a two-stage process: the initial XGBoost model is built using raw data, and once selected as the final model, the dataset is cleaned by (1) removing multicollinear features, (2) identifying outliers with Isolation Forest, and (3) selecting important features using SHAP analysis. The refined dataset as model 2 is then used to retrain XGBoost, which achieves high prediction accuracy across all outputs. A graphical user interface (GUI) is also developed to support material designers. Overall, the proposed framework significantly improves the prediction accuracy and minimizes the need for extensive experimental testing in UHPC mix design.

</details>


### [19] [Mechanical Strength Prediction of Steel-Polypropylene Fiber-based High-Performance Concrete Using Hybrid Machine Learning Algorithms](https://arxiv.org/abs/2512.21638)
*Jagaran Chakma,Zhiguang Zhou,Badhan Chakma*

Main category: cs.LG

TL;DR: 本研究开发并评估了三种机器学习模型来预测钢-聚丙烯纤维增强高性能混凝土的力学性能，其中ET-XGB模型在压缩和拉伸强度预测上表现最佳，RF-LGBM在弯曲强度预测上最稳定，SHAP分析揭示了纤维长径比和硅灰是最重要的影响因素。


<details>
  <summary>Details</summary>
Motivation: 高性能混凝土的力学性能预测对工程应用至关重要，传统实验方法耗时耗力。本研究旨在开发准确、可解释的机器学习模型来预测钢-聚丙烯纤维增强高性能混凝土的压缩强度、弯曲强度和拉伸强度，为混凝土配合比优化和结构性能评估提供有效工具。

Method: 研究采用了三种机器学习模型组合：Extra Trees与XGBoost（ET-XGB）、随机森林与LightGBM（RF-LGBM）、Transformer与XGBoost（Transformer-XGB）。基于已发表实验研究构建的广泛数据集，使用k折交叉验证、超参数优化、SHAP可解释性分析和不确定性分析来确保模型的鲁棒性和可解释性。

Result: ET-XGB模型整体表现最佳，测试R²值分别为：压缩强度0.994、弯曲强度0.944、拉伸强度0.978，且在压缩和拉伸强度预测上不确定性最低（约13-16%和30.4%）。RF-LGBM模型在弯曲强度预测上最稳定可靠（R² 0.977），不确定性最低（约5-33%）。Transformer-XGB模型虽然预测能力强，但不确定性最高。SHAP分析显示纤维长径比、硅灰和钢纤维含量是最重要的正向预测因子，而水含量和水胶比则有负面影响。

Conclusion: 机器学习模型能够为钢-聚丙烯纤维增强高性能混凝土的力学性能提供准确、可解释且可泛化的预测。这些模型为优化混凝土配合比设计和提升工程应用中的结构性能评估提供了有价值的工具，其中ET-XGB和RF-LGBM模型在不同性能预测方面各有优势。

Abstract: This research develops and evaluates machine learning models to predict the mechanical properties of steel-polypropylene fiber-reinforced high-performance concrete (HPC). Three model families were investigated: Extra Trees with XGBoost (ET-XGB), Random Forest with LightGBM (RF-LGBM), and Transformer with XGBoost (Transformer-XGB). The target properties included compressive strength (CS), flexural strength (FS), and tensile strength (TS), based on an extensive dataset compiled from published experimental studies. Model training involved k-fold cross-validation, hyperparameter optimization, Shapley additive explanations (SHAP), and uncertainty analysis to ensure both robustness and interpretability. Among the tested approaches, the ET-XGB model achieved the highest overall accuracy, with testing R^2 values of 0.994 for CS, 0.944 for FS, and 0.978 for TS and exhibited lowest uncertainty for CS and TS (approximately 13-16% and 30.4%, respectively). The RF-LGBM model provided the most stable and reliable predictions for FS (R^2 0.977), yielding the lowest uncertainty for FS (approximately 5-33%). The Transformer-XGB model demonstrated strong predictive capability (R^2 0.978 for TS and 0.967 for FS) but consistently showed the highest uncertainty, indicating reduced generalization reliability. SHAP analysis further indicated that fiber aspect ratios (AR1 and AR2), silica fume (Sfu), and steel fiber content (SF) were the most influential predictors of strength, whereas water content (W) and the water-binder ratio (w/b) consistently had negative effects. The findings confirm that machine learning models can provide accurate, interpretable, and generalizable predictions of HPC mechanical properties. These models offer valuable tools for optimizing concrete mix design and enhancing structural performance evaluation in engineering applications.

</details>


### [20] [A Comedy of Estimators: On KL Regularization in RL Training of LLMs](https://arxiv.org/abs/2512.21852)
*Vedant Shah,Johan Obando-Ceron,Vineet Jain,Brian Bartoldson,Bhavya Kailkhura,Sarthak Mittal,Glen Berseth,Pablo Samuel Castro,Yoshua Bengio,Nikolay Malkin,Moksh Jain,Siddarth Venkatraman,Aaron Courville*

Main category: cs.LG

TL;DR: 本文系统分析了LLM强化学习中KL散度估计器的不同配置方式及其梯度偏差对模型性能的影响，发现无偏梯度配置能带来更好的训练稳定性和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 尽管KL正则化在LLM强化学习中广泛应用，但实践中使用的KL散度估计器配置方式缺乏系统性研究，现有方法存在目标函数与实现之间的梯度偏差问题，影响模型训练效果。

Method: 通过理论分析不同KL估计器配置的梯度偏差，并实证研究Qwen2.5-7B、Llama-3.1-8B-Instruct和Qwen3-4B-Instruct-2507等模型在不同配置下的RL微调效果，评估其在分布内和分布外任务上的性能。

Result: 在在线策略设置中：(1)梯度有偏的估计器配置会导致训练不稳定；(2)使用无偏梯度配置的估计器在分布内和分布外任务上都表现更好。在离线策略设置中，KL正则化有助于稳定异步设置导致的训练过程。

Conclusion: KL散度估计器的配置选择对LLM强化学习训练至关重要，使用无偏梯度配置能显著提升训练稳定性和模型泛化能力，为实践中的KL正则化实现提供了重要指导。

Abstract: The reasoning performance of large language models (LLMs) can be substantially improved by training them with reinforcement learning (RL). The RL objective for LLM training involves a regularization term, which is the reverse Kullback-Leibler (KL) divergence between the trained policy and the reference policy. Since computing the KL divergence exactly is intractable, various estimators are used in practice to estimate it from on-policy samples. Despite its wide adoption, including in several open-source libraries, there is no systematic study analyzing the numerous ways of incorporating KL estimators in the objective and their effect on the downstream performance of RL-trained models. Recent works show that prevailing practices for incorporating KL regularization do not provide correct gradients for stated objectives, creating a discrepancy between the objective and its implementation. In this paper, we further analyze these practices and study the gradients of several estimators configurations, revealing how design choices shape gradient bias. We substantiate these findings with empirical observations by RL fine-tuning \texttt{Qwen2.5-7B}, \texttt{Llama-3.1-8B-Instruct} and \texttt{Qwen3-4B-Instruct-2507} with different configurations and evaluating their performance on both in- and out-of-distribution tasks. Through our analysis, we observe that, in on-policy settings: (1) estimator configurations with biased gradients can result in training instabilities; and (2) using estimator configurations resulting in unbiased gradients leads to better performance on in-domain as well as out-of-domain tasks. We also investigate the performance resulting from different KL configurations in off-policy settings and observe that KL regularization can help stabilize off-policy RL training resulting from asynchronous setups.

</details>


### [21] [Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation](https://arxiv.org/abs/2512.21866)
*Yiming Qian,Thorsten Neumann,Xueyining Huang,David Hardoon,Fei Gao,Yong Liu,Siow Mong Rick Goh*

Main category: cs.LG

TL;DR: 提出一种可解释、保护隐私的数据集蒸馏框架，用于协作式金融欺诈检测。通过将随机森林转换为透明规则区域，生成合成交易数据，在减少85-93%数据量的同时保持检测性能，并支持可解释性和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 解决金融欺诈检测中多机构协作时的数据隐私保护问题，同时需要保持模型的可解释性和检测性能。传统方法在数据共享时存在隐私泄露风险，且缺乏对决策过程的透明解释。

Method: 将训练好的随机森林转换为透明、轴对齐的规则区域（叶节点超矩形），在每个区域内均匀采样生成合成交易数据。通过规则区域统计（支持度、提升度）提供全局模式解释，为每个案例分配生成区域提供简洁的人类可读理由，并基于树投票分歧计算校准的不确定性。

Result: 在IEEE-CIS欺诈数据集（59万笔交易，三个机构集群）上，蒸馏数据集减少85-93%数据量（通常低于原始数据的15%），同时保持竞争力的精确度和微F1分数，AUC仅有适度下降。跨机构共享和增强合成数据提高了跨集群的精确度、召回率和AUC。真实与合成数据结构高度相似（最近邻余弦分析超过93%）。成员推理攻击在区分训练和保留记录时表现接近随机水平（约0.50），表明记忆风险低。使用分歧分数移除高不确定性合成点可进一步提升AUC（最高达0.687）并改善校准。

Conclusion: 树区域蒸馏实现了可信赖、可部署的欺诈分析，具有可解释的全局规则、带量化不确定性的逐案例理由，以及适合多机构设置和监管审计的强大隐私特性。该方法在隐私保护、可解释性和检测性能之间取得了良好平衡。

Abstract: We propose an explainable, privacy-preserving dataset distillation framework for collaborative financial fraud detection. A trained random forest is converted into transparent, axis-aligned rule regions (leaf hyperrectangles), and synthetic transactions are generated by uniformly sampling within each region. This produces a compact, auditable surrogate dataset that preserves local feature interactions without exposing sensitive original records. The rule regions also support explainability: aggregated rule statistics (for example, support and lift) describe global patterns, while assigning each case to its generating region gives concise human-readable rationales and calibrated uncertainty based on tree-vote disagreement.
  On the IEEE-CIS fraud dataset (590k transactions across three institution-like clusters), distilled datasets reduce data volume by 85% to 93% (often under 15% of the original) while maintaining competitive precision and micro-F1, with only a modest AUC drop. Sharing and augmenting with synthesized data across institutions improves cross-cluster precision, recall, and AUC. Real vs. synthesized structure remains highly similar (over 93% by nearest-neighbor cosine analysis). Membership-inference attacks perform at chance level (about 0.50) when distinguishing training from hold-out records, suggesting low memorization risk. Removing high-uncertainty synthetic points using disagreement scores further boosts AUC (up to 0.687) and improves calibration. Sensitivity tests show weak dependence on the distillation ratio (AUC about 0.641 to 0.645 from 6% to 60%).
  Overall, tree-region distillation enables trustworthy, deployable fraud analytics with interpretable global rules, per-case rationales with quantified uncertainty, and strong privacy properties suitable for multi-institution settings and regulatory audit.

</details>


### [22] [Causal-HM: Restoring Physical Generative Logic in Multimodal Anomaly Detection via Hierarchical Modulation](https://arxiv.org/abs/2512.21650)
*Xiao Liu,Junchen Jin,Yanjie Zhao,Zhixuan Xing*

Main category: cs.LG

TL;DR: 提出Causal-HM框架，通过显式建模物理过程到结果的因果关系，解决多模态异常检测中的因果盲点和异质性差距问题，在焊接质量检测中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态异常检测方法存在因果盲点，将过程模态（实时视频、音频、传感器）和结果模态（焊后图像）视为同等特征源，忽略了物理生成逻辑；同时高维视觉数据和低维传感器信号之间的异质性差距导致关键过程上下文被淹没。

Method: 提出Causal-HM统一多模态异常检测框架：1）传感器引导的CHM调制机制，利用低维传感器信号作为上下文指导高维视听特征提取；2）因果层次架构，强制执行单向生成映射以识别违反物理一致性的异常。

Result: 在新构建的Weld-4M基准测试中，Causal-HM在四个模态上实现了90.7%的SOTA I-AUROC性能。

Conclusion: 通过显式建模物理过程到结果的因果关系，Causal-HM框架有效解决了多模态异常检测中的因果盲点和异质性差距问题，在复杂制造过程中实现了卓越的异常检测性能。

Abstract: Multimodal Unsupervised Anomaly Detection (UAD) is critical for quality assurance in smart manufacturing, particularly in complex processes like robotic welding. However, existing methods often suffer from causal blindness, treating process modalities (e.g., real-time video, audio, and sensors) and result modalities (e.g., post-weld images) as equal feature sources, thereby ignoring the inherent physical generative logic. Furthermore, the heterogeneity gap between high-dimensional visual data and low-dimensional sensor signals frequently leads to critical process context being drowned out. In this paper, we propose Causal-HM, a unified multimodal UAD framework that explicitly models the physical Process to Result dependency. Specifically, our framework incorporates two key innovations: a Sensor-Guided CHM Modulation mechanism that utilizes low-dimensional sensor signals as context to guide high-dimensional audio-visual feature extraction , and a Causal-Hierarchical Architecture that enforces a unidirectional generative mapping to identify anomalies that violate physical consistency. Extensive experiments on our newly constructed Weld-4M benchmark across four modalities demonstrate that Causal-HM achieves a state-of-the-art (SOTA) I-AUROC of 90.7%. Code will be released after the paper is accepted.

</details>


### [23] [Rethinking Output Alignment For 1-bit Post-Training Quantization of Large Language Models](https://arxiv.org/abs/2512.21651)
*Dung Anh Hoang,Cuong Pham,Cuong Nguyen,Trung le,Jianfei Cai,Thanh-Toan Do*

Main category: cs.LG

TL;DR: 本文提出了一种针对1位大语言模型量化的数据感知后训练量化方法，通过考虑激活误差累积来改善输出匹配效果，相比现有方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在资源受限设备上部署困难，需要压缩技术。虽然后训练量化效率高，但1位量化（权重转换为±1）尤其具有挑战性，现有方法存在显著性能下降。特别是现有1位PTQ方法主要关注权重对齐而非输出对齐，而输出匹配方法虽然更直观，但在1位LLM中直接应用会导致性能下降。

Method: 研究1位LLM量化中输出匹配失败的原因和条件，提出一种新颖的数据感知PTQ方法，明确考虑激活误差累积，同时保持优化效率。

Result: 实验证明，该方法在最小开销下持续优于现有的1位PTQ方法。

Conclusion: 通过考虑激活误差累积的数据感知方法，可以有效解决1位LLM量化中输出匹配的问题，为资源受限设备上的高效部署提供了更好的解决方案。

Abstract: Large Language Models (LLMs) deliver strong performance across a wide range of NLP tasks, but their massive sizes hinder deployment on resource-constrained devices. To reduce their computational and memory burden, various compression techniques have been proposed, including quantization, pruning, and knowledge distillation. Among these, post-training quantization (PTQ) is widely adopted for its efficiency, as it requires no retraining and only a small dataset for calibration, enabling low-cost deployment. Recent advances for post-training quantization have demonstrated that even sub-4-bit methods can maintain most of the original model performance. However, 1-bit quantization that converts floating-point weights to \(\pm\)1, remains particularly challenging, as existing 1-bit PTQ methods often suffer from significant performance degradation compared to the full-precision models. Specifically, most of existing 1-bit PTQ approaches focus on weight alignment, aligning the full-precision model weights with those of the quantized models, rather than directly aligning their outputs. Although the output-matching approach objective is more intuitive and aligns with the quantization goal, naively applying it in 1-bit LLMs often leads to notable performance degradation. In this paper, we investigate why and under what conditions output-matching fails, in the context of 1-bit LLM quantization. Based on our findings, we propose a novel data-aware PTQ approach for 1-bit LLMs that explicitly accounts for activation error accumulation while keeping optimization efficient. Empirical experiments demonstrate that our solution consistently outperforms existing 1-bit PTQ methods with minimal overhead.

</details>


### [24] [LibContinual: A Comprehensive Library towards Realistic Continual Learning](https://arxiv.org/abs/2512.22029)
*Wenbin Li,Shangge Liu,Borui Kang,Yiyang Chen,KaXuan Lew,Yang Chen,Yinghuan Shi,Lei Wang,Yang Gao,Jiebo Luo*

Main category: cs.LG

TL;DR: LibContinual是一个用于持续学习的统一框架库，解决了现有方法碎片化、评估不一致的问题，通过严格在线设置揭示了主流方法在现实约束下的性能下降。


<details>
  <summary>Details</summary>
Motivation: 持续学习领域方法多样但研究碎片化，缺乏统一框架，导致公平比较和可复现研究困难。现有评估存在不现实的假设，高估了方法的实际应用价值。

Method: 提出LibContinual库，采用高内聚低耦合的模块化架构，集成19种代表性算法。通过该框架系统识别并研究三个隐含假设：离线数据可访问性、无限制内存资源、任务内语义同质性。

Result: 使用严格在线CL设置、统一内存预算协议和类别随机化设置进行综合分析，发现许多代表性CL方法在现实约束下性能显著下降，揭示了现有评估的局限性。

Conclusion: 需要资源感知和语义鲁棒的CL策略，LibContinual作为基础工具包为现实持续学习研究提供支持，促进更实际的方法评估和开发。

Abstract: A fundamental challenge in Continual Learning (CL) is catastrophic forgetting, where adapting to new tasks degrades the performance on previous ones. While the field has evolved with diverse methods, this rapid surge in diverse methodologies has culminated in a fragmented research landscape. The lack of a unified framework, including inconsistent implementations, conflicting dependencies, and varying evaluation protocols, makes fair comparison and reproducible research increasingly difficult. To address this challenge, we propose LibContinual, a comprehensive and reproducible library designed to serve as a foundational platform for realistic CL. Built upon a high-cohesion, low-coupling modular architecture, LibContinual integrates 19 representative algorithms across five major methodological categories, providing a standardized execution environment. Meanwhile, leveraging this unified framework, we systematically identify and investigate three implicit assumptions prevalent in mainstream evaluation: (1) offline data accessibility, (2) unregulated memory resources, and (3) intra-task semantic homogeneity. We argue that these assumptions often overestimate the real-world applicability of CL methods. Through our comprehensive analysis using strict online CL settings, a novel unified memory budget protocol, and a proposed category-randomized setting, we reveal significant performance drops in many representative CL methods when subjected to these real-world constraints. Our study underscores the necessity of resource-aware and semantically robust CL strategies, and offers LibContinual as a foundational toolkit for future research in realistic continual learning. The source code is available from \href{https://github.com/RL-VIG/LibContinual}{https://github.com/RL-VIG/LibContinual}.

</details>


### [25] [From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation](https://arxiv.org/abs/2512.22031)
*Nagham Osman,Vittorio Lembo,Giovanni Bottegoni,Laura Toni*

Main category: cs.LG

TL;DR: 该研究首次将"hit-like分子生成"作为独立任务，探索生成模型能否替代药物发现流程中的命中识别步骤，提出了专门的评估框架并测试了多种生成模型。


<details>
  <summary>Details</summary>
Motivation: 传统的高通量筛选耗时耗力，虚拟筛选方法仍然成本高昂。虽然深度学习生成模型能从头生成新化合物，但用机器学习完全替代整个药物发现流程极具挑战性。因此，研究者探索生成模型能否专门替代流程中的命中识别步骤。

Method: 将hit-like分子生成作为独立任务，提出专门评估框架，整合理化性质、结构和生物活性标准，形成多阶段过滤流程来定义hit-like化学空间。对两种自回归模型和一种扩散模型在不同数据集和训练设置下进行基准测试，使用标准指标和靶点特异性对接评分评估输出。

Result: 模型能够生成有效、多样且具有生物相关性的化合物，覆盖多个靶点。部分选定的GSK-3β命中分子被合成并在体外实验中确认具有活性。同时发现了当前评估指标和可用训练数据的关键局限性。

Conclusion: 这是首个将hit-like分子生成作为独立任务的研究，证明生成模型能够支持药物发现流程中的命中识别阶段，但当前评估指标和训练数据存在局限性需要改进。

Abstract: Hit identification is a critical yet resource-intensive step in the drug discovery pipeline, traditionally relying on high-throughput screening of large compound libraries. Despite advancements in virtual screening, these methods remain time-consuming and costly. Recent progress in deep learning has enabled the development of generative models capable of learning complex molecular representations and generating novel compounds de novo. However, using ML to replace the entire drug-discovery pipeline is highly challenging. In this work, we rather investigate whether generative models can replace one step of the pipeline: hit-like molecule generation. To the best of our knowledge, this is the first study to explicitly frame hit-like molecule generation as a standalone task and empirically test whether generative models can directly support this stage of the drug discovery pipeline. Specifically, we investigate if such models can be trained to generate hit-like molecules, enabling direct incorporation into, or even substitution of, traditional hit identification workflows. We propose an evaluation framework tailored to this task, integrating physicochemical, structural, and bioactivity-related criteria within a multi-stage filtering pipeline that defines the hit-like chemical space. Two autoregressive and one diffusion-based generative models were benchmarked across various datasets and training settings, with outputs assessed using standard metrics and target-specific docking scores. Our results show that these models can generate valid, diverse, and biologically relevant compounds across multiple targets, with a few selected GSK-3$β$ hits synthesized and confirmed active in vitro. We also identify key limitations in current evaluation metrics and available training data.

</details>


### [26] [Unifying Learning Dynamics and Generalization in Transformers Scaling Law](https://arxiv.org/abs/2512.22088)
*Chiwun Yang*

Main category: cs.LG

TL;DR: 该研究将Transformer语言模型的学习动态形式化为ODE系统，分析SGD训练多层Transformer在序列数据上的收敛性，揭示了泛化误差随计算资源增长的相变规律：优化阶段指数衰减，统计阶段幂律衰减Θ(C^{-1/6})。


<details>
  <summary>Details</summary>
Motivation: 尽管缩放定律在LLM开发中经验验证有效，但其理论基础仍不明确。现有分析多基于简化模型，缺乏对真实条件下多层Transformer训练的理论理解。

Method: 将Transformer语言模型的学习动态形式化为常微分方程系统，近似为核行为。严格分析多层Transformer在任意数据分布的序列到序列数据上的SGD训练过程，建立理论框架分析泛化误差收敛性。

Result: 建立了泛化误差的理论上界，揭示了明显的相变现象：初始优化阶段误差随计算成本C指数衰减；超过特定资源阈值后进入统计阶段，泛化误差按幂律Θ(C^{-1/6})衰减。理论还推导了模型大小、训练时间和数据集大小的独立缩放定律。

Conclusion: 该研究为LLM缩放定律提供了严格的理论基础，揭示了训练过程中的相变机制，并量化了不同资源变量对泛化性能的独立影响，为大规模语言模型的高效训练提供了理论指导。

Abstract: The scaling law, a cornerstone of Large Language Model (LLM) development, predicts improvements in model performance with increasing computational resources. Yet, while empirically validated, its theoretical underpinnings remain poorly understood. This work formalizes the learning dynamics of transformer-based language models as an ordinary differential equation (ODE) system, then approximates this process to kernel behaviors. Departing from prior toy-model analyses, we rigorously analyze stochastic gradient descent (SGD) training for multi-layer transformers on sequence-to-sequence data with arbitrary data distribution, closely mirroring real-world conditions. Our analysis characterizes the convergence of generalization error to the irreducible risk as computational resources scale with data, especially during the optimization process.
  We establish a theoretical upper bound on excess risk characterized by a distinct phase transition. In the initial optimization phase, the excess risk decays exponentially relative to the computational cost ${\sf C}$. However, once a specific resource allocation threshold is crossed, the system enters a statistical phase, where the generalization error follows a power-law decay of $Θ(\mathsf{C}^{-1/6})$. Beyond this unified framework, our theory derives isolated scaling laws for model size, training time, and dataset size, elucidating how each variable independently governs the upper bounds of generalization.

</details>


### [27] [Dynamic Feedback Engines: Layer-Wise Control for Self-Regulating Continual Learning](https://arxiv.org/abs/2512.21743)
*Hengyi Wu,Zhenyi Wang,Heng Huang*

Main category: cs.LG

TL;DR: 提出了一种基于熵感知的持续学习方法，通过动态反馈机制根据各层的熵值进行调节，平衡过拟合和欠拟合问题，提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法通常对所有层进行统一处理，在稳定性和可塑性之间进行权衡。然而，不同层在分类任务时自然表现出不同的不确定性（熵）。高熵层容易欠拟合，无法捕捉任务特定模式；低熵层容易过拟合，变得过于自信和专门化。需要解决这种不平衡问题。

Method: 提出熵感知持续学习方法，采用动态反馈机制根据每层的熵值进行调节。具体来说，降低高熵层的熵以缓解欠拟合，增加过度自信层的熵以减轻过拟合。这种自适应调节鼓励模型收敛到更宽的局部最小值，从而提高泛化能力。该方法具有通用性，可无缝集成到基于重放和基于正则化的方法中。

Result: 在多个数据集上的实验表明，该方法相比最先进的持续学习基线方法取得了显著的性能提升。

Conclusion: 通过熵感知的动态层调节机制，有效平衡了持续学习中的过拟合和欠拟合问题，提高了模型的泛化能力，为持续学习提供了一种新的有效方法。

Abstract: Continual learning aims to acquire new tasks while preserving performance on previously learned ones, but most methods struggle with catastrophic forgetting. Existing approaches typically treat all layers uniformly, often trading stability for plasticity or vice versa. However, different layers naturally exhibit varying levels of uncertainty (entropy) when classifying tasks. High-entropy layers tend to underfit by failing to capture task-specific patterns, while low-entropy layers risk overfitting by becoming overly confident and specialized. To address this imbalance, we propose an entropy-aware continual learning method that employs a dynamic feedback mechanism to regulate each layer based on its entropy. Specifically, our approach reduces entropy in high-entropy layers to mitigate underfitting and increases entropy in overly confident layers to alleviate overfitting. This adaptive regulation encourages the model to converge to wider local minima, which have been shown to improve generalization. Our method is general and can be seamlessly integrated with both replay- and regularization-based approaches. Experiments on various datasets demonstrate substantial performance gains over state-of-the-art continual learning baselines.

</details>


### [28] [Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs](https://arxiv.org/abs/2512.21915)
*Yafeng Tang,Xiaoou Ding,Jianzhuo Du,Zishuo Yan,Zhuang Ma,Zheng Liang,Zekai Qian,Hongzhi Wang*

Main category: cs.LG

TL;DR: DATE是一个多样性感知的表格数据生成框架，通过将异构数据划分为多个分布不同的子集，利用大语言模型为每个子集生成高质量标记数据，并使用多臂赌博机算法平衡生成数据的多样性与质量。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的表格数据具有天然的异构性和分布多样性，现有生成模型难以获得适用于多样化数据生成的通用好模型。需要解决在异构数据环境下生成高质量且分布多样的表格数据的问题。

Method: 1) 将原始异构数据有效划分为多个分布不同的子集，为上下文学习准备高质量且分布不同的示例；2) 利用大语言模型通过决策树推理作为反馈，探索划分后分布的多样性，为每个子集生成高质量标记数据；3) 设计基于多臂赌博机的采样算法，平衡生成数据的多样性与质量，解决贪婪选择在异构环境下不适用的问题。

Result: 在表格分类和回归基准测试中，DATE持续优于最先进的基于GAN和LLM的方法。平均而言，仅使用100个生成数据就能实现23.75%的错误率降低。实验证明DATE生成的数据可以改进直接偏好优化的准确性，并增强LLM在目标数据上的推理能力。

Conclusion: DATE框架成功解决了异构表格数据生成中多样性与质量的平衡问题，通过分布划分、LLM生成和智能采样算法，显著提升了生成数据的质量和实用性，为机器学习应用提供了大规模、高质量的数据支持。

Abstract: Tabular data generation has become increasingly essential for enabling robust machine learning applications, which require large-scale, high-quality data. Existing solutions leverage generative models to learn original data distributions. However, real-world data are naturally heterogeneous with diverse distributions, making it challenging to obtain a universally good model for diverse data generation. To address this limitation, we introduce Diversity-Aware Tabular data gEnerator (DATE), a framework that (i) prepares high-quality and distributionally distinct examples for in-context learning by effectively partitioning the original heterogeneous data into multiple diverse subsets; (ii) harnesses Large Language Models (LLMs) to explore the diversity of the partitioned distribution with decision tree reasoning as feedback, generating high-quality labeled data for each subset. However, the massive generated data inherently involves a trade-off between diversity and quality. To integrate this issue, existing solutions greedily select the validation-best data. However, we prove that the selection in heterogeneous settings does not possess the greedy-choice property, and design a Multi-Arm Bandit-based sampling algorithm that balances the diversity and quality of generated data. Extensive experiments on tabular classification and regression benchmarks demonstrate that DATE consistently outperforms state-of-the-art GAN-based and LLM-based methods. On average, DATE achieves a 23.75% reduction in error rate with just 100 generated data. Empirically, we demonstrate that data generated by DATE can improve the accuracy of Direct Preference Optimization (DPO) and enhance the reasoning capability of LLMs on the target data. Code is available at https://github.com/windblow32/DATE.

</details>


### [29] [Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms](https://arxiv.org/abs/2512.21925)
*Kongchang Zhou,Tingyu Zhang,Wei Chen,Fang Kong*

Main category: cs.LG

TL;DR: 提出混合CMAB-T框架，结合离线数据和在线交互来解决传统在线和离线方法的局限性，通过混合CUCB算法利用离线数据指导探索并加速收敛，同时通过在线交互纠正离线数据的偏差。


<details>
  <summary>Details</summary>
Motivation: 传统组合多臂老虎机（CMAB-T）研究主要分为在线学习和离线学习两种范式。在线方法存在交互成本高、适应速度慢的问题，而离线方法受限于数据集质量和缺乏探索能力。为了解决这两种方法的互补性弱点，需要一种能够整合离线数据和在线交互的新框架。

Method: 提出混合CMAB-T框架，设计混合CUCB算法。该算法利用离线数据来指导探索过程并加速收敛，同时策略性地引入在线交互来弥补离线数据集覆盖不足或存在分布偏差的问题。

Result: 理论分析证明了算法的遗憾界，表明当有高质量离线数据时，混合CUCB显著优于纯在线方法；当离线数据有限或存在偏差时，能有效纠正纯离线方法的偏差。实证结果进一步验证了算法的持续优势。

Conclusion: 混合CMAB-T框架成功整合了离线数据和在线交互的优势，通过混合CUCB算法在理论上和实证上都表现出优越性能，为解决组合多臂老虎机问题提供了一种更有效的解决方案。

Abstract: The problem of combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) has been extensively studied. Prior work primarily focuses on either the online setting where an agent learns about the unknown environment through iterative interactions, or the offline setting where a policy is learned solely from logged data. However, each of these paradigms has inherent limitations: online algorithms suffer from high interaction costs and slow adaptation, while offline methods are constrained by dataset quality and lack of exploration capabilities. To address these complementary weaknesses, we propose hybrid CMAB-T, a new framework that integrates offline data with online interaction in a principled manner. Our proposed hybrid CUCB algorithm leverages offline data to guide exploration and accelerate convergence, while strategically incorporating online interactions to mitigate the insufficient coverage or distributional bias of the offline dataset. We provide theoretical guarantees on the algorithm's regret, demonstrating that hybrid CUCB significantly outperforms purely online approaches when high-quality offline data is available, and effectively corrects the bias inherent in offline-only methods when the data is limited or misaligned. Empirical results further demonstrate the consistent advantage of our algorithm.

</details>


### [30] [Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing](https://arxiv.org/abs/2512.22024)
*Wesley S. Leite,Rodrigo C. de Lamare,Yuriy Zakharov,Wei Liu,Martin Haardt*

Main category: cs.LG

TL;DR: 提出可变窗口尺寸空间平滑框架，增强稀疏线性阵列的协阵列DOA估计性能，通过压缩平滑孔径来改进信号与噪声子空间分离


<details>
  <summary>Details</summary>
Motivation: 传统固定窗口协阵列MUSIC方法在处理稀疏线性阵列时存在性能限制，需要改进信号与噪声子空间的分离效果

Method: 提出VWS-CA-MUSIC和VWS-CA-rMUSIC算法，通过压缩平滑孔径，用未扰动的低秩附加项替换部分扰动的秩一外积，保持信号子空间张成

Result: 仿真显示相对于固定窗口协阵列MUSIC方法，在稀疏几何结构下获得显著性能提升和复杂度降低

Conclusion: 可变窗口尺寸空间平滑框架有效增强了协阵列DOA估计性能，同时推导了可辨识性边界条件

Abstract: In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.

</details>


### [31] [Scaling Adversarial Training via Data Selection](https://arxiv.org/abs/2512.22069)
*Youran Ye,Dejin Wang,Ajinkya Bhandare*

Main category: cs.LG

TL;DR: 提出选择性对抗训练，仅扰动每个小批次中的关键样本子集，通过两种选择标准（边界采样和梯度匹配采样）减少50%对抗计算，同时保持或超越完整PGD对抗训练的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: PGD对抗训练计算成本高，所有训练样本都经过相同的迭代内循环优化，尽管它们对鲁棒性的贡献不均等。这种效率低下促使研究者提出选择性对抗训练方法。

Method: 提出选择性对抗训练，仅扰动每个小批次中的关键样本子集。引入两种选择标准：1) 边界采样：优先选择靠近决策边界的样本；2) 梯度匹配采样：选择梯度与主导批次优化方向对齐的样本。仅对选定子集生成对抗样本，其余样本使用混合目标进行干净训练。

Result: 在MNIST和CIFAR-10上的实验表明，所提方法达到与完整PGD对抗训练相当甚至更好的鲁棒性，同时将对抗计算减少高达50%。

Conclusion: 明智的样本选择足以实现可扩展的对抗鲁棒性，选择性对抗训练在保持鲁棒性的同时显著降低了计算成本。

Abstract: Projected Gradient Descent (PGD) is a strong and widely used first-order adversarial attack, yet its computational cost scales poorly, as all training samples undergo identical iterative inner-loop optimization despite contributing unequally to robustness. Motivated by this inefficiency, we propose \emph{Selective Adversarial Training}, which perturbs only a subset of critical samples in each minibatch. Specifically, we introduce two principled selection criteria: (1) margin-based sampling, which prioritizes samples near the decision boundary, and (2) gradient-matching sampling, which selects samples whose gradients align with the dominant batch optimization direction. Adversarial examples are generated only for the selected subset, while the remaining samples are trained cleanly using a mixed objective. Experiments on MNIST and CIFAR-10 show that the proposed methods achieve robustness comparable to, or even exceeding, full PGD adversarial training, while reducing adversarial computation by up to $50\%$, demonstrating that informed sample selection is sufficient for scalable adversarial robustness.

</details>


### [32] [Explainable Multimodal Regression via Information Decomposition](https://arxiv.org/abs/2512.22102)
*Zhaozhao Ma,Shujian Yu*

Main category: cs.LG

TL;DR: 基于部分信息分解的多模态回归框架，通过量化各模态的独特、冗余和协同信息，提升预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态回归方法缺乏量化各模态贡献及其交互作用的原理性工具，限制了多模态融合的可解释性。

Method: 提出基于部分信息分解的多模态回归框架，通过高斯性假设实现PID项的解析计算，并引入条件独立性正则化来分离各模态的独特信息。

Result: 在六个真实数据集（包括大规模脑年龄预测）上的实验表明，该框架在预测准确性和可解释性方面优于现有方法，并能实现高效推理的模态选择。

Conclusion: 该研究提供了一个原理性的多模态回归框架，能够量化模态贡献并提升模型可解释性，为高效的多模态推理提供了工具。

Abstract: Multimodal regression aims to predict a continuous target from heterogeneous input sources and typically relies on fusion strategies such as early or late fusion. However, existing methods lack principled tools to disentangle and quantify the individual contributions of each modality and their interactions, limiting the interpretability of multimodal fusion. We propose a novel multimodal regression framework grounded in Partial Information Decomposition (PID), which decomposes modality-specific representations into unique, redundant, and synergistic components. The basic PID framework is inherently underdetermined. To resolve this, we introduce inductive bias by enforcing Gaussianity in the joint distribution of latent representations and the transformed response variable (after inverse normal transformation), thereby enabling analytical computation of the PID terms. Additionally, we derive a closed-form conditional independence regularizer to promote the isolation of unique information within each modality. Experiments on six real-world datasets, including a case study on large-scale brain age prediction from multimodal neuroimaging data, demonstrate that our framework outperforms state-of-the-art methods in both predictive accuracy and interpretability, while also enabling informed modality selection for efficient inference. Implementation is available at https://github.com/zhaozhaoma/PIDReg.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [33] [Exact $q$-exponential Multi-Mode Solutions with Independent Centres and Power-Law Relaxation in the Plastino-Plastino Equation](https://arxiv.org/abs/2512.21353)
*Airton Deppman*

Main category: physics.soc-ph

TL;DR: 该论文首次提出了Plastino-Plastino非线性扩散方程在任意幂律漂移下的精确多模态解，通过允许每个q-指数模态具有独立的时间依赖中心，消除了漂移项中的所有模态间耦合，实现了中心运动、概率含量和宽度的完全可分离演化方程。


<details>
  <summary>Details</summary>
Motivation: 研究Plastino-Plastino非线性扩散方程的精确解，该方程在非广延热力学、分形空间扩散和多尺度弛豫动力学中具有重要应用，但之前缺乏完整的解析解。

Method: 通过引入具有独立时间依赖中心的q-指数模态，使漂移项中的模态间耦合消失，从而获得完全可分离的演化方程。瞬态模态保持恒定宽度并通过精确的q-指数（幂律）弛豫衰减，而单个吸引子模态不可逆地吸收全部概率通量。

Result: 获得了该方程的首次精确多模态解，所有先前已知的精确结果都作为特例被恢复。该解统一了Tsallis非广延热力学、分形空间扩散和多尺度弛豫动力学，可直接应用于夸克-胶子等离子体中的重夸克喷注、分形介质中的Lévy飞行和城市人口再分布等问题。

Conclusion: 该研究提供了Plastino-Plastino非线性扩散方程的完整解析解框架，无需近似即可精确闭合层次结构，从任意初始条件驱动系统达到已知的稳态q-指数状态，为多个物理领域的应用提供了理论基础。

Abstract: We present the first exact, multi-mode solutions to the Plastino-Plastino nonlinear diffusion equation with arbitrary power-law drift. By allowing each $q$-exponential mode to have its own independent, time-dependent centre, all inter-mode couplings in the drift term vanish, yielding fully separable evolution equations for centre motion, probability content, and (for the attractor mode) width. Transient modes exhibit constant width and decay via exact q-exponential (power-law) relaxation, while a single attractor mode irreversibly absorbs the entire probability flux, with fixed amplitude and time-growing width, driving the system to the known stationary q-exponential state from arbitrary initial conditions. The hierarchy closes exactly without approximation. These analytic solutions unify Tsallis nonextensive thermodynamics, fractal-space diffusion, and multi-scale relaxation dynamics, with direct applications to heavy-quark jets in quark-gluon plasma, Lévy flights in fractal media, and urban population redistribution. All previous exact results are recovered as special cases.

</details>


### [34] [The Transformation of Broadband Demand: From Discretionary Service to Essential Infrastructure (2010-2024)](https://arxiv.org/abs/2512.21356)
*Samir Orujov,Ilgar Ismayilov,Jeyhun Huseynzade*

Main category: physics.soc-ph

TL;DR: 宽带需求在2010-2024年间发生根本转变：从价格敏感变为价格不敏感，表明宽带已成为必需品而非奢侈品


<details>
  <summary>Details</summary>
Motivation: 研究宽带是否已成为价格变化免疫的必需品，以及COVID-19是否是其需求转变的关键驱动因素

Method: 使用33个欧洲国家15年面板数据（2010-2024），采用双向固定效应模型和Driscoll-Kraay标准误，分析价格弹性变化

Result: 1. 疫情前：东欧伙伴国家需求弹性高（ε=-0.61），欧盟国家中等弹性（ε=-0.12）；2. 2020-2024年：两地区均收敛至接近零弹性；3. 安慰剂测试显示转变始于2015年而非2020年；4. 价格测量方式显著影响推断结果

Conclusion: 宽带已从可自由支配服务转变为基本公用事业，政策重点应从可负担性补贴转向普遍基础设施部署

Abstract: Has broadband become a necessity good immune to price changes? Using a 15-year panel of 33 European countries (2010--2024) and two-way fixed effects with Driscoll--Kraay standard errors, we document a fundamental transformation in broadband demand. Pre-COVID, Eastern Partnership countries exhibited highly elastic demand ($\varepsilon = -0.61$, p$<$0.001) -- a 10\% price reduction increased subscriptions by 6\% -- while EU countries showed moderate elasticity ($\varepsilon = -0.12$, p$<$0.05). By 2020--2024, both regions converged to near-zero elasticity, with price changes having no detectable effect on adoption. Crucially, placebo tests reveal this transformation began in 2015, not 2020, indicating a decade-long digital integration process rather than a COVID-19 shock. We further demonstrate that price measurement critically affects inference: income-relative prices (as \% of GNI) yield significant results in 100\% of specifications, compared to only 25\% for PPP-adjusted prices. These findings have immediate policy relevance: as broadband transitions from discretionary service to essential utility, policy emphasis must shift from affordability subsidies to universal infrastructure deployment.

</details>


### [35] [The Wiener Path Integral Interpretation of the 3:1 Combat Rule](https://arxiv.org/abs/2512.21957)
*Wei Liang,Ming Zhong*

Main category: physics.soc-ph

TL;DR: 该研究提出使用维纳路径积分框架建模军事战斗动态，将随机效应纳入兰彻斯特平方定律，并用于评估经典的3:1战斗规则。


<details>
  <summary>Details</summary>
Motivation: 传统兰彻斯特平方定律忽略了战斗中的随机效应，而经典的3:1战斗规则缺乏严格的理论基础。需要建立物理信息化的理论框架来分析和量化不确定战斗系统中的获胜概率。

Method: 采用维纳路径积分框架，将随机效应整合到兰彻斯特平方定律中。使用半解析的Rayleigh-Ritz方法计算攻击方的获胜概率，并分析3:1规则的有效性条件。

Result: 数值结果表明，3:1规则的适用性高度依赖于特定参数范围，主要取决于敌对双方相对战斗效能比和可承受的损耗容忍度。该规则并非普遍适用，而是有条件地成立。

Conclusion: 该工作建立了统计力学与军事运筹学之间的物理信息理论桥梁，为分析不确定战斗系统提供了新的数学框架，并揭示了经典战斗规则的参数依赖性。

Abstract: The Wiener path integral framework is proposed to model military combat dynamics by incorporating the neglected stochastic effects to the Lanchester's square law. This framework is applied to evaluate the empirical 3:1 combat rule, which posits that an attacker requires a threefold force superiority to achieve victory. Specifically, the attacker's winning probability is computed utilizing a semi-analytical Rayleigh-Ritz method. Numerical results demonstrate that the validity of the rule critically depends on specific parameter regimes, primarily contingent upon the relative combat effectiveness ratio between the opposing forces and the tolerance for attrition. This work establishes a physics-informed theoretical bridge between statistical mechanics and military operations research for analyzing uncertain combat systems.

</details>


### [36] [Classifying Urban Regions by Aggregated Pollutant Weather Correlation Strength: A Spatiotemporal Study](https://arxiv.org/abs/2512.22080)
*Koyena Ghosh,Suchismita Banerjee,Urna Basu,Banasri Basu*

Main category: physics.soc-ph

TL;DR: 该研究开发了一个基于熵的统计框架，用于分析印度多个城市空气污染物与气象变量之间的静态和时间依赖性，通过PCA整合多种相关性指标，提供统一的污染物-气象相互作用评估方法。


<details>
  <summary>Details</summary>
Motivation: 理解污染物与气象之间的相互作用对环境风险评估至关重要，需要开发能够分析多个城市中空气污染物与气象变量之间静态和时间依赖性的统一框架。

Method: 开发基于熵的统计框架，使用Pearson相关、互信息、相对条件熵等线性和非线性度量量化依赖性，通过PCA整合这些异质指标为统一的相关性评分，并使用时滞互信息和转移熵分析时间依赖性。

Result: 相对湿度通常导致污染物浓度变化，而环境温度往往滞后，显示相反的因果影响；互信息在零滞后时达到峰值并迅速衰减，表明强烈的短期相互作用但持久性有限；敏感性分析显示框架稳健。

Conclusion: 提出的框架为评估不同地点和时间的复杂污染物-气象相互作用提供了统一且可解释的方法，能够将城市分类为不同的相互作用机制，有助于环境风险评估。

Abstract: Understanding pollutant meteorology interactions is essential for environmental risk assessment. This study develops an entropy-based statistical framework to analyze static and temporal dependencies between urban air pollutants and meteorological variables across multiple Indian cities. Dependence is quantified using complementary linear and nonlinear measures, including Pearson correlation, mutual information, and relative conditional entropy. A key methodological contribution is a PCA based composite indexing framework that integrates these heterogeneous metrics into a unified and interpretable correlation score. For each pollutant meteorological pair within a city, PCA is used to extract a joint variability index, while spatial variability is assessed by aggregating correlations across cities. These indices are further combined to derive a comprehensive city-level correlation score that represents overall pollutant meteorology coupling strength and enables classification of cities into distinct interaction regimes. Sensitivity analysis, performed by systematically excluding individual variable pairs, demonstrates the robustness of the framework, with no single pair exerting disproportionate influence. Temporal dependencies are examined using transfer entropy and time-delayed mutual information. Results indicate that relative humidity generally leads changes in pollutant concentrations, whereas ambient temperature tends to lag, highlighting contrasting causal influences. Mutual information peaks at zero lag and decays rapidly, indicating strong short term interactions with limited persistence. Overall, the proposed framework provides a unified and interpretable approach for assessing complex pollutant meteorology interactions across diverse locations and time.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [37] [From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration](https://arxiv.org/abs/2512.21360)
*Shuide Wen,Yu Sun,Beier Ku,Zhi Gao,Lijun Ma,Yang Yang,Can Jiao*

Main category: cs.AI

TL;DR: 本研究提出了一种基于多模态大语言模型的多智能体系统，用于标准化HTP绘画测试评估，通过定量和定性分析验证了该系统能达到专家级解释水平。


<details>
  <summary>Details</summary>
Motivation: HTP绘画测试作为临床心理学中广泛使用的投射技术，长期以来面临评分标准不统一、依赖检查者主观经验、缺乏统一量化编码系统等挑战，需要开发标准化评估工具。

Method: 采用多模态大语言模型构建多智能体协作框架，通过角色分工将特征识别与心理推理解耦，整合社会心理学视角和去污名化叙事，纠正视觉幻觉。

Result: 定量实验显示MLLM解释与人类专家解释的平均语义相似度约为0.75（标准差约0.05），在结构化专家数据集中相似度提升至0.85，达到专家级基线理解水平。定性分析表明系统能产生具有高生态效度和内在一致性的心理报告。

Conclusion: 多模态大模型作为投射评估标准化工具具有潜力，提出的多智能体框架通过角色分工为数字心理健康服务提供了新范式。

Abstract: Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examiners subjective experience, and a lack of a unified quantitative coding system.
  Results: Quantitative experiments showed that the mean semantic similarity between Multimodal Large Language Model (MLLM) interpretations and human expert interpretations was approximately 0.75 (standard deviation about 0.05). In structurally oriented expert data sets, this similarity rose to 0.85, indicating expert-level baseline comprehension. Qualitative analyses demonstrated that the multi-agent system, by integrating social-psychological perspectives and destigmatizing narratives, effectively corrected visual hallucinations and produced psychological reports with high ecological validity and internal coherence.
  Conclusions: The findings confirm the potential of multimodal large models as standardized tools for projective assessment. The proposed multi-agent framework, by dividing roles, decouples feature recognition from psychological inference and offers a new paradigm for digital mental-health services.
  Keywords: House-Tree-Person test; multimodal large language model; multi-agent collaboration; cosine similarity; computational psychology; artificial intelligence

</details>


### [38] [A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers](https://arxiv.org/abs/2512.21365)
*Chung-Chin Shih,Ti-Rong Wu,Ting Han Wei,Yu-Shan Hsu,Hung Guei,I-Chen Wu*

Main category: cs.AI

TL;DR: 该研究分析了使用相关区域搜索和相关区域模式表技术的计算机围棋生死题求解器在解决围棋生死题时的行为表现，发现了求解器与人类棋手在解题策略上的差异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索当前最先进的计算机围棋求解器在解决围棋生死题时的表现，特别是使用相关区域搜索和相关区域模式表技术时，求解器与人类棋手解题方法的差异。

Method: 使用相关区域搜索和相关区域模式表技术的计算机围棋求解器，对围棋大师赵治勋《死活辞典》中的七个生死题进行求解分析。

Result: 1. 求解器能为每个问题识别出关键区域；2. 发现了一系列模式，包括一些罕见模式；3. 在两个问题上找到了与给定答案不同的解法；4. 发现了求解器的两个问题：对罕见模式价值判断错误，以及倾向于直接求活而非最大化实地。

Conclusion: 计算机围棋求解器在生死题求解中表现出与人类不同的策略偏好，存在对罕见模式价值判断和求活策略方面的局限性，未来需要改进这些方面以更接近人类棋手的解题思维。

Abstract: This paper analyzes the behavior of solving Life-and-Death (L&D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We examined the solutions derived by relevance-zone based solvers on seven L&D problems from the renowned book "Life and Death Dictionary" written by Cho Chikun, a Go grandmaster, and found several interesting results. First, for each problem, the solvers identify a relevance-zone that highlights the critical areas for solving. Second, the solvers discover a series of patterns, including some that are rare. Finally, the solvers even find different answers compared to the given solutions for two problems. We also identified two issues with the solver: (a) it misjudges values of rare patterns, and (b) it tends to prioritize living directly rather than maximizing territory, which differs from the behavior of human Go players. We suggest possible approaches to address these issues in future work. Our code and data are available at https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ.

</details>


### [39] [Three-way decision with incomplete information based on similarity and satisfiability](https://arxiv.org/abs/2512.21421)
*Junfang Luo,Mengjun Hu,Keyun Qin*

Main category: cs.AI

TL;DR: 本文在回顾完整信息下三支决策的计算和概念两种表述基础上，将其推广到更实用的不完备信息场景，提出了相似度度量、近似性概念和公式满足度等新方法。


<details>
  <summary>Details</summary>
Motivation: 现有三支决策方法主要处理完备信息，但在实际应用中不完备信息更为常见。需要将完备信息下的两种表述（计算和概念）推广到不完备信息场景，以增强三支决策的实用性和适用性。

Method: 1. 计算表述：提出对象相似度度量作为等价关系的推广，基于此讨论使用α-相似类和对象近似性的两种三支决策方法。2. 概念表述：提出公式满足度度量作为完备信息下满足关系的量化推广，基于此研究使用α-意义集和公式置信度的两种三支决策方法。

Result: 提出了不完备信息下三支决策的四种新方法：基于α-相似类和对象近似性的计算表述方法，以及基于α-意义集和公式置信度的概念表述方法。其中对象近似性概念和两种概念表述方法为不完备信息分析指出了新的研究方向。

Conclusion: 成功将三支决策从完备信息推广到不完备信息场景，提出了相似度度量和公式满足度等新概念，为不完备信息下的三支决策提供了新的理论框架和方法论，特别是对象近似性概念和概念表述方法为未来研究开辟了有前景的方向。

Abstract: Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a briefly review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using alpha-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using alpha-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.

</details>


### [40] [LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis](https://arxiv.org/abs/2512.21482)
*Fanwei Zeng,Changtao Miao,Jing Huang,Zhiya Tan,Shutao Gong,Xiaoming Yu,Yang Wang,Huazhe Tan,Weibin Yao,Jianshu Li*

Main category: cs.AI

TL;DR: LogicLens是一个统一的视觉-文本协同推理框架，用于分析文本中心伪造，通过跨线索感知思维链机制实现深度推理，并在多个基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC技术的快速发展，复杂的文本中心伪造对社会安全和信息真实性构成重大威胁。现有方法通常局限于粗粒度的视觉分析，缺乏深度推理能力，且将检测、定位和解释视为独立子任务，忽略了它们之间的内在联系。

Method: 提出LogicLens统一框架，采用跨线索感知思维链机制进行视觉-文本协同推理，通过加权多任务奖励函数进行GRPO优化。同时设计了PR²（感知器、推理器、审查器）流水线生成高质量注释，并构建了包含5,397张图像的RealText数据集。

Result: 在T-IC13的零样本评估中，LogicLens比专用框架高出41.4%，比GPT-4o高出23.4%的宏平均F1分数。在密集文本T-SROIE数据集上，在mF1、CSS和宏平均F1指标上显著领先其他MLLM方法。

Conclusion: LogicLens通过统一的视觉-文本协同推理框架，有效解决了文本中心伪造分析中的挑战，在多个基准测试中表现出优越性能，为伪造检测提供了新的解决方案。

Abstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis and lack the capacity for sophisticated reasoning. Moreover, they typically treat detection, grounding, and explanation as discrete sub-tasks, overlooking their intrinsic relationships for holistic performance enhancement. To address these challenges, we introduce LogicLens, a unified framework for Visual-Textual Co-reasoning that reformulates these objectives into a joint task. The deep reasoning of LogicLens is powered by our novel Cross-Cues-aware Chain of Thought (CCT) mechanism, which iteratively cross-validates visual cues against textual logic. To ensure robust alignment across all tasks, we further propose a weighted multi-task reward function for GRPO-based optimization. Complementing this framework, we first designed the PR$^2$ (Perceiver, Reasoner, Reviewer) pipeline, a hierarchical and iterative multi-agent system that generates high-quality, cognitively-aligned annotations. Then, we constructed RealText, a diverse dataset comprising 5,397 images with fine-grained annotations, including textual explanations, pixel-level segmentation, and authenticity labels for model training. Extensive experiments demonstrate the superiority of LogicLens across multiple benchmarks. In a zero-shot evaluation on T-IC13, it surpasses the specialized framework by 41.4% and GPT-4o by 23.4% in macro-average F1 score. Moreover, on the challenging dense-text T-SROIE dataset, it establishes a significant lead over other MLLM-based methods in mF1, CSS, and the macro-average F1. Our dataset, model, and code will be made publicly available.

</details>


### [41] [Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model](https://arxiv.org/abs/2512.21540)
*Yanhao Li,Lu Ma,Jiaran Zhang,Lexiang Tang,Wentao Zhang,Guibo Luo*

Main category: cs.AI

TL;DR: 提出Leash框架，通过自适应长度惩罚和奖励塑造，在保持任务性能的同时显著减少LLM推理长度


<details>
  <summary>Details</summary>
Motivation: 现有固定长度惩罚方法难以调优，无法适应LLM不断发展的推理能力，导致准确性和简洁性之间的次优权衡

Method: 将长度控制建模为约束优化问题，采用拉格朗日对偶方法动态调整惩罚系数：生成超过目标长度时加强惩罚，较短时放松惩罚

Result: 在Deepseek-R1-Distill-Qwen-1.5B和Qwen3-4B-Thinking-2507上，Leash将平均推理长度减少60%，同时在数学推理、编码和指令跟随等任务上保持竞争力

Conclusion: Leash为开发可控高效LLM提供了实用有效的范式，平衡了推理能力和计算预算

Abstract: Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and reward SHaping), a reinforcement learning framework for efficient reasoning in LLMs. We formulate length control as a constrained optimization problem and employ a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. When generations exceed the target length, the penalty is intensified; when they are shorter, it is relaxed. This adaptive mechanism guides models toward producing concise reasoning without sacrificing task performance. Experiments on Deepseek-R1-Distill-Qwen-1.5B and Qwen3-4B-Thinking-2507 show that Leash reduces the average reasoning length by 60% across diverse tasks - including in-distribution mathematical reasoning and out-of-distribution domains such as coding and instruction following - while maintaining competitive performance. Our work thus presents a practical and effective paradigm for developing controllable and efficient LLMs that balance reasoning capabilities with computational budgets.

</details>


### [42] [A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning](https://arxiv.org/abs/2512.21583)
*Zelin Zang,Wenyi Gu,Siqi Ma,Dan Yang,Yue Shen,Zhu Zhang,Guohui Fan,Wing-Kuen Ling,Fuji Yang*

Main category: cs.AI

TL;DR: 基于LLaVA构建的诊断框架，结合视觉语言对齐与逻辑正则化推理，提升医学多模态诊断的准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 随着医学领域大语言模型和视觉语言模型的快速发展，简单整合临床文本和医学影像并不能保证可靠的推理。现有多模态模型常产生幻觉或不一致的思维链，限制了临床信任度

Method: 提出基于LLaVA的诊断框架，包含：文本和图像的输入编码器、跨模态对齐的投影模块、将诊断任务分解为步骤的推理控制器，以及将逐步前提组装成可验证结论的逻辑树生成器

Result: 在MedXpertQA等基准测试中，该方法提高了诊断准确性，在多模态任务上产生更可解释的推理轨迹，同时在纯文本设置中保持竞争力

Conclusion: 这些结果表明该方法朝着可信赖的多模态医学AI迈出了有希望的一步

Abstract: With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or inconsistent chains of thought, limiting clinical trust. We propose a diagnostic framework built upon LLaVA that combines vision-language alignment with logic-regularized reasoning. The system includes an input encoder for text and images, a projection module for cross-modal alignment, a reasoning controller that decomposes diagnostic tasks into steps, and a logic tree generator that assembles stepwise premises into verifiable conclusions. Evaluations on MedXpertQA and other benchmarks show that our method improves diagnostic accuracy and yields more interpretable reasoning traces on multimodal tasks, while remaining competitive on text-only settings. These results suggest a promising step toward trustworthy multimodal medical AI.

</details>


### [43] [Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design](https://arxiv.org/abs/2512.21623)
*Takahide Suzuki,Kazuki Nakanishi,Takashi Fujiwara,Hideyuki Shimizu*

Main category: cs.AI

TL;DR: OrchestRA是一个人类在环的多智能体平台，将生物学、化学和药理学统一为自主发现引擎，通过动态反馈循环实现治疗药物设计


<details>
  <summary>Details</summary>
Motivation: 当前治疗药物发现面临专业领域碎片化以及计算设计与生理验证之间的执行鸿沟挑战，现有生成AI模型通常只是被动助手而非自主执行者

Method: OrchestRA采用多智能体架构：由Orchestrator协调，生物学家智能体利用大规模知识图谱进行深度推理识别靶点，化学家智能体自主检测结构口袋进行从头设计或药物重定位，药理学家智能体通过PBPK模拟评估候选药物，形成动态反馈循环

Result: 该平台建立了动态反馈循环，药代动力学和毒性特征直接触发结构重新优化，将药物发现从随机搜索转变为可编程的循证工程学科

Conclusion: OrchestRA通过自主执行与人类指导的无缝集成，民主化了治疗药物设计，为药物发现提供了新的范式

Abstract: Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.

</details>


### [44] [Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing](https://arxiv.org/abs/2512.21626)
*Hong Xie,Haoran Gu,Yanying Huang,Tao Tan,Defu Lian*

Main category: cs.AI

TL;DR: 本文提出了一种针对LLM应用、边缘智能等资源分配问题的多臂赌博机变体，建立了优先资源共享机制下的理论框架，设计了匹配下界的算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM应用、边缘智能等场景中的资源分配问题，需要一种能够处理优先资源共享机制的多臂赌博机模型。传统模型无法有效处理容量随机且按优先级分配的情况。

Method: 提出了MSB-PRS模型：M个臂，K个play，每个臂有随机容量，每个容量单位有奖励函数，play有优先级权重。设计了MSB-PRS-OffOpt算法（复杂度O(MK³)）寻找最优分配策略，并基于此设计了近似UCB算法。

Result: 证明了实例独立下界Ω(α₁σ√KMT)和实例依赖下界Ω(α₁σ²M/Δ ln T)。设计的算法上界分别匹配下界至√K ln KT和α₁K²因子，在理论上有紧致性保证。

Conclusion: 成功建立了优先资源共享机制下的多臂赌博机理论框架，解决了由特殊非线性组合效用函数带来的优化和学习挑战，为实际资源分配问题提供了理论基础和算法解决方案。

Abstract: This paper proposes a variant of multiple-play stochastic bandits tailored to resource allocation problems arising from LLM applications, edge intelligence, etc. The model is composed of $M$ arms and $K$ plays. Each arm has a stochastic number of capacities, and each unit of capacity is associated with a reward function. Each play is associated with a priority weight. When multiple plays compete for the arm capacity, the arm capacity is allocated in a larger priority weight first manner. Instance independent and instance dependent regret lower bounds of $Ω( α_1 σ\sqrt{KM T} )$ and $Ω(α_1 σ^2 \frac{M}Δ \ln T)$ are proved, where $α_1$ is the largest priority weight and $σ$ characterizes the reward tail. When model parameters are given, we design an algorithm named \texttt{MSB-PRS-OffOpt} to locate the optimal play allocation policy with a computational complexity of $O(MK^3)$. Utilizing \texttt{MSB-PRS-OffOpt} as a subroutine, an approximate upper confidence bound (UCB) based algorithm is designed, which has instance independent and instance dependent regret upper bounds matching the corresponding lower bound up to factors of $ \sqrt{K \ln KT }$ and $α_1 K^2$ respectively. To this end, we address nontrivial technical challenges arising from optimizing and learning under a special nonlinear combinatorial utility function induced by the prioritized resource sharing mechanism.

</details>


### [45] [Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets](https://arxiv.org/abs/2512.21775)
*Matyas Bohacek,Ignacio Vilanova Echavarri*

Main category: cs.AI

TL;DR: 提出合规评级方案(CRS)框架，用于评估数据集在透明度、问责制和安全性方面的合规性，并发布开源Python库实现该框架


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能(GAI)的快速发展依赖于大规模开源数据集，但这些数据集通常采用不受限制和不透明的数据收集方式。现有文献多关注GAI模型的开发和应用，而忽略了数据集创建过程中的伦理和法律考量。此外，数据集在共享、编辑和复制过程中，其来源、合法性和安全性信息往往丢失。

Method: 引入合规评级方案(CRS)框架，基于数据溯源技术开发开源Python库，评估数据集在透明度、问责制和安全性方面的合规性。该库既能评估现有数据集的CRS，也能指导新数据集的负责任抓取和构建。

Result: 开发了一个开源Python库，能够无缝集成到现有的数据集处理和AI训练流程中。该库具有反应性和前瞻性双重功能，既能评估现有数据集的合规性，又能指导新数据集的负责任构建。

Conclusion: CRS框架和配套工具填补了GAI数据集伦理和法律考量的空白，通过数据溯源技术确保数据集在整个生命周期中的透明度、问责制和安全性，促进生成式人工智能的负责任发展。

Abstract: Generative Artificial Intelligence (GAI) has experienced exponential growth in recent years, partly facilitated by the abundance of large-scale open-source datasets. These datasets are often built using unrestricted and opaque data collection practices. While most literature focuses on the development and applications of GAI models, the ethical and legal considerations surrounding the creation of these datasets are often neglected. In addition, as datasets are shared, edited, and further reproduced online, information about their origin, legitimacy, and safety often gets lost. To address this gap, we introduce the Compliance Rating Scheme (CRS), a framework designed to evaluate dataset compliance with critical transparency, accountability, and security principles. We also release an open-source Python library built around data provenance technology to implement this framework, allowing for seamless integration into existing dataset-processing and AI training pipelines. The library is simultaneously reactive and proactive, as in addition to evaluating the CRS of existing datasets, it equally informs responsible scraping and construction of new datasets.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [46] [Index-Tracking Portfolio Construction and Rebalancing under Bayesian Sparse Modelling and Uncertainty Quantification](https://arxiv.org/abs/2512.22109)
*Dimitrios Roxanas*

Main category: q-fin.CP

TL;DR: 本文从运筹学角度研究稀疏指数跟踪组合的构建与再平衡，强调不确定性量化和可实施性，通过贝叶斯方法控制跟踪误差、组合稀疏度和换手率


<details>
  <summary>Details</summary>
Motivation: 传统指数跟踪方法往往忽视不确定性量化和实际实施约束，本文旨在开发一个既能紧密跟踪指数，又能控制组合中股票数量（稀疏性）和再平衡换手率的框架，特别强调从运筹学角度的可实施性

Method: 将指数跟踪建模为高维线性回归问题，使用拉普拉斯先验诱导稀疏性，通过经验贝叶斯随机近似校准全局收缩参数，采用近端朗之万型MCMC算法近似后验分布，基于后验样本设计再平衡规则

Result: 开发了一个完整的贝叶斯框架，能够量化跟踪误差、组合构成和再平衡操作的不确定性，提出的再平衡规则通过幅度阈值和后验激活概率来平衡预期跟踪误差与换手率和组合规模

Conclusion: 该方法为指数跟踪提供了从组合构建到再平衡的完整决策支持工具，通过S&P 500指数的案例研究展示了如何在实际投资决策中应用这些工具来权衡跟踪精度与实施成本

Abstract: We study the construction and rebalancing of sparse index-tracking portfolios from an operational research perspective, with explicit emphasis on uncertainty quantification and implementability. The decision variables are portfolio weights constrained to sum to one; the aims are to track a reference index closely while controlling the number of names and the turnover induced by rebalancing. We cast index tracking as a high-dimensional linear regression of index returns on constituent returns, and employ a sparsity-inducing Laplace prior on the weights. A single global shrinkage parameter controls the trade-off between tracking error and sparsity, and is calibrated by an empirical-Bayes stochastic approximation scheme. Conditional on this calibration, we approximate the posterior distribution of the portfolio weights using proximal Langevin-type Markov chain Monte Carlo algorithms tailored to the budget constraint. This yields posterior uncertainty on tracking error, portfolio composition and prospective rebalancing moves. Building on these posterior samples, we propose rules for rebalancing that gate trades through magnitude-based thresholds and posterior activation probabilities, thereby trading off expected tracking error against turnover and portfolio size. A case study on tracking the S&P~500 index is carried out to showcase how our tools shape the decision process from portfolio construction to rebalancing.

</details>
